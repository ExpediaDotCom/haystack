{"infrastructureState":{ "version": 3, "terraform_version": "0.11.1", "serial": 2, "lineage": "d532b697-52fd-4b3a-8f77-2ebf6a9696be", "modules": [ { "path": [ "root" ], "outputs": { "aa_app_namespace": { "sensitive": false, "type": "string", "value": "aa-apps" }, "cassandra_hostname": { "sensitive": false, "type": "string", "value": "cassandra" }, "cassandra_port": { "sensitive": false, "type": "string", "value": "9042" }, "elasticsearch_hostname": { "sensitive": false, "type": "string", "value": "elasticsearch" }, "elasticsearch_port": { "sensitive": false, "type": "string", "value": "9200" }, "graphite_enabled": { "sensitive": false, "type": "string", "value": "false" }, "graphite_hostname": { "sensitive": false, "type": "string", "value": "monitoring-influxdb-graphite.kube-system.svc" }, "graphite_port": { "sensitive": false, "type": "string", "value": "2003" }, "k8s_app_namespace": { "sensitive": false, "type": "string", "value": "haystack-apps" }, "k8s_cluster_name": { "sensitive": false, "type": "string", "value": "minikube" }, "kafka_hostname": { "sensitive": false, "type": "string", "value": "kafka-service.haystack-apps.svc.cluster.local" }, "kafka_port": { "sensitive": false, "type": "string", "value": "9092" } }, "resources": {}, "depends_on": [] }, { "path": [ "root", "haystack-infrastructure" ], "outputs": { "cassandra_hostname": { "sensitive": false, "type": "string", "value": "cassandra" }, "cassandra_port": { "sensitive": false, "type": "string", "value": "9042" }, "elasticsearch_hostname": { "sensitive": false, "type": "string", "value": "elasticsearch" }, "elasticsearch_port": { "sensitive": false, "type": "string", "value": "9200" }, "kafka_hostname": { "sensitive": false, "type": "string", "value": "kafka-service" }, "kafka_port": { "sensitive": false, "type": "string", "value": "9092" } }, "resources": {}, "depends_on": [] }, { "path": [ "root", "k8s-addons" ], "outputs": { "aa_app_namespace": { "sensitive": false, "type": "string", "value": "aa-apps" }, "graphite_hostname": { "sensitive": false, "type": "string", "value": "monitoring-influxdb-graphite.kube-system.svc" }, "graphite_port": { "sensitive": false, "type": "string", "value": "2003" }, "k8s_app_namespace": { "sensitive": false, "type": "string", "value": "haystack-apps" } }, "resources": {}, "depends_on": [] }, { "path": [ "root", "haystack-infrastructure", "cassandra" ], "outputs": { "cassandra_hostname": { "sensitive": false, "type": "string", "value": "cassandra" }, "cassandra_port": { "sensitive": false, "type": "string", "value": "9042" } }, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.container_port", "local.deployment_yaml_file_path", "local.image", "local.service_port" ], "primary": { "id": "14220dd933ffe26939206d93503444a2d245dee98044d42c60926befa590dcd4", "attributes": { "id": "14220dd933ffe26939206d93503444a2d245dee98044d42c60926befa590dcd4", "rendered": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: cassandra\n name: cassandra\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: cassandra\n template:\n metadata:\n labels:\n k8s-app: cassandra\n spec:\n containers:\n - name: cassandra\n image: cassandra:3.11.0\n resources:\n limits:\n memory: 1224Mi\n requests:\n memory: 1224Mi\n env:\n - name: \"MAX_HEAP_SIZE\"\n value: \"512m\"\n - name: \"HEAP_NEWSIZE\"\n value: \"512m\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: cassandra\n name: cassandra\n namespace: haystack-apps\nspec:\n ports:\n - port: 9042\n targetPort: 9042\n selector:\n k8s-app: cassandra", "template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n memory: ${memory_limit}Mi\n requests:\n memory: ${memory_limit}Mi\n env:\n - name: \"MAX_HEAP_SIZE\"\n value: \"${jvm_memory_limit}m\"\n - name: \"HEAP_NEWSIZE\"\n value: \"${jvm_memory_limit}m\"\n nodeSelector:\n ${node_selecter_label}\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}", "vars.%": "10", "vars.app_name": "cassandra", "vars.container_port": "9042", "vars.cpu_limit": "100m", "vars.image": "cassandra:3.11.0", "vars.jvm_memory_limit": "512", "vars.memory_limit": "1224", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "9042" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml" ], "primary": { "id": "2461528686714611053", "attributes": { "id": "2461528686714611053", "triggers.%": "1", "triggers.template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: cassandra\n name: cassandra\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: cassandra\n template:\n metadata:\n labels:\n k8s-app: cassandra\n spec:\n containers:\n - name: cassandra\n image: cassandra:3.11.0\n resources:\n limits:\n memory: 1224Mi\n requests:\n memory: 1224Mi\n env:\n - name: \"MAX_HEAP_SIZE\"\n value: \"512m\"\n - name: \"HEAP_NEWSIZE\"\n value: \"512m\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: cassandra\n name: cassandra\n namespace: haystack-apps\nspec:\n ports:\n - port: 9042\n targetPort: 9042\n selector:\n k8s-app: cassandra" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-infrastructure", "es" ], "outputs": { "elasticsearch_hostname": { "sensitive": false, "type": "string", "value": "elasticsearch" }, "elasticsearch_service_port": { "sensitive": false, "type": "string", "value": "9200" } }, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.container_port", "local.deployment_yaml_file_path", "local.es_docker_image", "local.service_port" ], "primary": { "id": "361839350861f393f9694bf6c8b643cc888f2d3846ac44d2593d0bff4556f909", "attributes": { "id": "361839350861f393f9694bf6c8b643cc888f2d3846ac44d2593d0bff4556f909", "rendered": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: elasticsearch\n name: elasticsearch\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: elasticsearch\n template:\n metadata:\n labels:\n k8s-app: elasticsearch\n spec:\n containers:\n - name: elasticsearch\n image: elasticsearch:5-alpine\n resources:\n limits:\n memory: 1224Mi\n requests:\n cpu: 100m\n memory: 1224Mi\n env:\n - name: \"ES_JAVA_OPTS\"\n value: \"-Xms512m -Xmx512m\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: elasticsearch\n name: elasticsearch\n namespace: haystack-apps\nspec:\n ports:\n - port: 9200\n targetPort: 9200\n selector:\n k8s-app: elasticsearch", "template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n env:\n - name: \"ES_JAVA_OPTS\"\n value: \"-Xms${jvm_memory_limit}m -Xmx${jvm_memory_limit}m\"\n nodeSelector:\n ${node_selecter_label}\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}", "vars.%": "10", "vars.app_name": "elasticsearch", "vars.container_port": "9200", "vars.cpu_limit": "100m", "vars.image": "elasticsearch:5-alpine", "vars.jvm_memory_limit": "512", "vars.memory_limit": "1224", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "9200" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml" ], "primary": { "id": "8674032481214041160", "attributes": { "id": "8674032481214041160", "triggers.%": "1", "triggers.template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: elasticsearch\n name: elasticsearch\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: elasticsearch\n template:\n metadata:\n labels:\n k8s-app: elasticsearch\n spec:\n containers:\n - name: elasticsearch\n image: elasticsearch:5-alpine\n resources:\n limits:\n memory: 1224Mi\n requests:\n cpu: 100m\n memory: 1224Mi\n env:\n - name: \"ES_JAVA_OPTS\"\n value: \"-Xms512m -Xmx512m\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: elasticsearch\n name: elasticsearch\n namespace: haystack-apps\nspec:\n ports:\n - port: 9200\n targetPort: 9200\n selector:\n k8s-app: elasticsearch" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-infrastructure", "kafka" ], "outputs": { "kafka_port": { "sensitive": false, "type": "string", "value": "9092" }, "kafka_service_name": { "sensitive": false, "type": "string", "value": "kafka-service" } }, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.container_port", "local.deployment_yaml_file_path", "local.image", "local.service_port", "local.topics", "module.zookeeper" ], "primary": { "id": "38140e265cf6a68fa9585eb372097e8701a595d74ecfee3aa93c1f8df8d7bcc0", "attributes": { "id": "38140e265cf6a68fa9585eb372097e8701a595d74ecfee3aa93c1f8df8d7bcc0", "rendered": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: kafka-service\n name: kafka-service\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: kafka-service\n template:\n metadata:\n labels:\n k8s-app: kafka-service\n spec:\n containers:\n - name: kafka-service\n image: wurstmeister/kafka:0.11.0.1\n resources:\n limits:\n memory: 1224Mi\n requests:\n cpu: 100m\n memory: 1224\n ports:\n - containerPort: 9092\n hostPort: 9092\n env:\n - name: \"KAFKA_ADVERTISED_HOST_NAME\"\n value: \"192.168.99.105\"\n - name: \"KAFKA_ADVERTISED_PORT\"\n value: \"9092\"\n - name: \"KAFKA_ZOOKEEPER_CONNECT\"\n value: \"zookeeper:2181\"\n - name: \"KAFKA_CREATE_TOPICS\"\n value: \"proto-spans:1:1,metricpoints:1:1,mdm:1:1,span-buffer:1:1,graph-nodes:1:1,ewma-metrics:1:1,constant-metrics:1:1,pewma-metrics:1:1,anomalies:1:1,aa-metrics:1:1,mapped-metrics:1:1\"\n - name: \"KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE\"\n value: \"LogAppendTime\"\n - name: \"KAFKA_HEAP_OPTS\"\n value: \"-Xmx512m -Xms512m\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: kafka-service\n name: kafka-service\n namespace: haystack-apps\nspec:\n ports:\n - port: 9092\n targetPort: 9092\n selector:\n k8s-app: kafka-service", "template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_limit}\n memory: ${memory_limit}\n ports:\n - containerPort: ${container_port}\n hostPort: ${container_port}\n env:\n - name: \"KAFKA_ADVERTISED_HOST_NAME\"\n value: \"${host_name}\"\n - name: \"KAFKA_ADVERTISED_PORT\"\n value: \"${service_port}\"\n - name: \"KAFKA_ZOOKEEPER_CONNECT\"\n value: \"${zk_endpoint}\"\n - name: \"KAFKA_CREATE_TOPICS\"\n value: \"${topics}\"\n - name: \"KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE\"\n value: \"LogAppendTime\"\n - name: \"KAFKA_HEAP_OPTS\"\n value: \"-Xmx${jvm_memory_limit}m -Xms${jvm_memory_limit}m\"\n nodeSelector:\n ${node_selecter_label}\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}", "vars.%": "13", "vars.app_name": "kafka-service", "vars.container_port": "9092", "vars.cpu_limit": "100m", "vars.host_name": "192.168.99.105", "vars.image": "wurstmeister/kafka:0.11.0.1", "vars.jvm_memory_limit": "512", "vars.memory_limit": "1224", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "9092", "vars.topics": "proto-spans:1:1,metricpoints:1:1,mdm:1:1,span-buffer:1:1,graph-nodes:1:1,ewma-metrics:1:1,constant-metrics:1:1,pewma-metrics:1:1,anomalies:1:1,aa-metrics:1:1,mapped-metrics:1:1", "vars.zk_endpoint": "zookeeper:2181" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml" ], "primary": { "id": "246431673335860473", "attributes": { "id": "246431673335860473", "triggers.%": "1", "triggers.template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: kafka-service\n name: kafka-service\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: kafka-service\n template:\n metadata:\n labels:\n k8s-app: kafka-service\n spec:\n containers:\n - name: kafka-service\n image: wurstmeister/kafka:0.11.0.1\n resources:\n limits:\n memory: 1224Mi\n requests:\n cpu: 100m\n memory: 1224\n ports:\n - containerPort: 9092\n hostPort: 9092\n env:\n - name: \"KAFKA_ADVERTISED_HOST_NAME\"\n value: \"192.168.99.105\"\n - name: \"KAFKA_ADVERTISED_PORT\"\n value: \"9092\"\n - name: \"KAFKA_ZOOKEEPER_CONNECT\"\n value: \"zookeeper:2181\"\n - name: \"KAFKA_CREATE_TOPICS\"\n value: \"proto-spans:1:1,metricpoints:1:1,mdm:1:1,span-buffer:1:1,graph-nodes:1:1,ewma-metrics:1:1,constant-metrics:1:1,pewma-metrics:1:1,anomalies:1:1,aa-metrics:1:1,mapped-metrics:1:1\"\n - name: \"KAFKA_LOG_MESSAGE_TIMESTAMP_TYPE\"\n value: \"LogAppendTime\"\n - name: \"KAFKA_HEAP_OPTS\"\n value: \"-Xmx512m -Xms512m\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: kafka-service\n name: kafka-service\n namespace: haystack-apps\nspec:\n ports:\n - port: 9092\n targetPort: 9092\n selector:\n k8s-app: kafka-service" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "aa_apps_resource_limits" ], "outputs": {}, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.deployment_yaml_file_path" ], "primary": { "id": "7a2046a02c9bb8c6c58d40494c1bc2abe6b1eef2860343b8363b1d655b837111", "attributes": { "id": "7a2046a02c9bb8c6c58d40494c1bc2abe6b1eef2860343b8363b1d655b837111", "rendered": "apiVersion: v1\nkind: ResourceQuota\nmetadata:\n name: aa-apps-resource-limits\nspec:\n hard:\n requests.cpu: 1\n requests.memory: 1Gi\n limits.cpu: 1\n limits.memory: 1Gi", "template": "apiVersion: v1\nkind: ResourceQuota\nmetadata:\n name: aa-apps-resource-limits\nspec:\n hard:\n requests.cpu: ${cpu_limit}\n requests.memory: ${memory_limit}\n limits.cpu: ${cpu_limit}\n limits.memory: ${memory_limit}", "vars.%": "2", "vars.cpu_limit": "1", "vars.memory_limit": "1Gi" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "monitoring-addons" ], "outputs": {}, "resources": {}, "depends_on": [] }, { "path": [ "root", "k8s-addons", "traefik-addon" ], "outputs": { "aa_app_namespace": { "sensitive": false, "type": "string", "value": "aa-apps" }, "k8s_app_namespace": { "sensitive": false, "type": "string", "value": "haystack-apps" } }, "resources": { "data.template_file.traefik_cluster_addon_config": { "type": "template_file", "depends_on": [ "local.k8s_app_namespace" ], "primary": { "id": "bcea9ab711d15f6b3175c8c3f3753041df17dfb81e44c9e7ab7cdb17207ac562", "attributes": { "id": "bcea9ab711d15f6b3175c8c3f3753041df17dfb81e44c9e7ab7cdb17207ac562", "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\n labels:\n app: traefik-ingress-controller\ndata:\n traefik.toml: |\n # traefik.toml\n logLevel = \"INFO\"\n defaultEntryPoints = [\"http\"]\n [entryPoints]\n [entryPoints.http]\n address = \":80\"\n compress = false\n [kubernetes]\n [web]\n address = \":8080\"\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: traefik-ingress-controller\nrules:\n - apiGroups:\n - \"\"\n resources:\n - pods\n - services\n - endpoints\n - secrets\n verbs:\n - get\n - list\n - watch\n - apiGroups:\n - extensions\n resources:\n - ingresses\n verbs:\n - get\n - list\n - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: traefik-ingress-controller\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n name: traefik-ingress-controller\n namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\n labels:\n k8s-app: traefik-haystack\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: traefik-ingress-controller\n template:\n metadata:\n labels:\n k8s-app: traefik-ingress-controller\n name: traefik-ingress-controller\n spec:\n serviceAccountName: traefik-ingress-controller\n terminationGracePeriodSeconds: 60\n volumes:\n - name: config\n configMap:\n name: traefik-ingress-controller\n containers:\n - image: traefik:v1.7.3\n name: traefik-ingress-controller\n livenessProbe:\n tcpSocket:\n port: 80\n failureThreshold: 3\n initialDelaySeconds: 10\n periodSeconds: 10\n successThreshold: 1\n timeoutSeconds: 2\n volumeMounts:\n - mountPath: /config\n name: config\n resources:\n limits:\n memory: 512Mi\n requests:\n memory: 128Mi\n ports:\n - containerPort: 80\n - containerPort: 8080\n - containerPort: 443\n args:\n - --configfile=/config/traefik.toml\n nodeSelector:\n kubernetes.io/hostname: minikube\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\nspec:\n type: NodePort\n ports:\n - port: 80\n name: http\n targetPort: 80\n nodePort: 32300\n selector:\n k8s-app: traefik-ingress-controller\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-ui\n namespace: haystack-apps\n annotations:\n kubernetes.io/ingress.class: traefik\nspec:\n rules:\n - host: haystack.local\n http:\n paths:\n - path: /\n backend:\n serviceName: haystack-ui\n servicePort: 80\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-http-span-collector\n namespace: haystack-apps\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefix\nspec:\n rules:\n - host: haystack.local\n http:\n paths:\n - path: /span\n backend:\n serviceName: http-span-collector\n servicePort: 80\n---\n\n", "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: ${traefik_name}\n namespace: kube-system\n labels:\n app: ${traefik_name}\ndata:\n traefik.toml: |\n # traefik.toml\n logLevel = \"INFO\"\n defaultEntryPoints = [\"http\"]\n [entryPoints]\n [entryPoints.http]\n address = \":80\"\n compress = false\n [kubernetes]\n [web]\n address = \":8080\"\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: ${traefik_name}\nrules:\n - apiGroups:\n - \"\"\n resources:\n - pods\n - services\n - endpoints\n - secrets\n verbs:\n - get\n - list\n - watch\n - apiGroups:\n - extensions\n resources:\n - ingresses\n verbs:\n - get\n - list\n - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: ${traefik_name}\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: ${traefik_name}\nsubjects:\n- kind: ServiceAccount\n name: ${traefik_name}\n namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: ${traefik_name}\n namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n name: ${traefik_name}\n namespace: kube-system\n labels:\n k8s-app: traefik-haystack\nspec:\n replicas: ${traefik_replicas}\n selector:\n matchLabels:\n k8s-app: ${traefik_name}\n template:\n metadata:\n labels:\n k8s-app: ${traefik_name}\n name: ${traefik_name}\n spec:\n serviceAccountName: ${traefik_name}\n terminationGracePeriodSeconds: 60\n volumes:\n - name: config\n configMap:\n name: ${traefik_name}\n containers:\n - image: ${traefik_image}\n name: ${traefik_name}\n livenessProbe:\n tcpSocket:\n port: 80\n failureThreshold: 3\n initialDelaySeconds: 10\n periodSeconds: 10\n successThreshold: 1\n timeoutSeconds: 2\n volumeMounts:\n - mountPath: /config\n name: config\n resources:\n limits:\n memory: 512Mi\n requests:\n memory: 128Mi\n ports:\n - containerPort: 80\n - containerPort: 8080\n - containerPort: 443\n args:\n - --configfile=/config/traefik.toml\n nodeSelector:\n ${node_selecter_label}\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: ${traefik_name}\n namespace: kube-system\nspec:\n type: NodePort\n ports:\n - port: 80\n name: http\n targetPort: 80\n nodePort: ${node_port}\n selector:\n k8s-app: ${traefik_name}\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-ui\n namespace: ${k8s_app_namespace}\n annotations:\n kubernetes.io/ingress.class: traefik\nspec:\n rules:\n - host: ${haystack_ui_cname}\n http:\n paths:\n - path: /\n backend:\n serviceName: haystack-ui\n servicePort: 80\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-http-span-collector\n namespace: ${k8s_app_namespace}\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefix\nspec:\n rules:\n - host: ${haystack_ui_cname}\n http:\n paths:\n - path: /span\n backend:\n serviceName: http-span-collector\n servicePort: 80\n---\n\n", "vars.%": "7", "vars.haystack_ui_cname": "haystack.local", "vars.k8s_app_namespace": "haystack-apps", "vars.node_port": "32300", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.traefik_image": "traefik:v1.7.3", "vars.traefik_name": "traefik-ingress-controller", "vars.traefik_replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.aa_app_namespace": { "type": "null_resource", "depends_on": [ "local.aa_app_namespace" ], "primary": { "id": "6015516601915557690", "attributes": { "id": "6015516601915557690" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.haystack_app_namespace": { "type": "null_resource", "depends_on": [ "local.k8s_app_namespace" ], "primary": { "id": "3850282158806672875", "attributes": { "id": "3850282158806672875" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.traefik_cluster_addon": { "type": "null_resource", "depends_on": [ "data.template_file.traefik_cluster_addon_config", "null_resource.aa_app_namespace", "null_resource.haystack_app_namespace" ], "primary": { "id": "6683836611142639533", "attributes": { "id": "6683836611142639533", "triggers.%": "1", "triggers.template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\n labels:\n app: traefik-ingress-controller\ndata:\n traefik.toml: |\n # traefik.toml\n logLevel = \"INFO\"\n defaultEntryPoints = [\"http\"]\n [entryPoints]\n [entryPoints.http]\n address = \":80\"\n compress = false\n [kubernetes]\n [web]\n address = \":8080\"\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: traefik-ingress-controller\nrules:\n - apiGroups:\n - \"\"\n resources:\n - pods\n - services\n - endpoints\n - secrets\n verbs:\n - get\n - list\n - watch\n - apiGroups:\n - extensions\n resources:\n - ingresses\n verbs:\n - get\n - list\n - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: traefik-ingress-controller\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n name: traefik-ingress-controller\n namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\n labels:\n k8s-app: traefik-haystack\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: traefik-ingress-controller\n template:\n metadata:\n labels:\n k8s-app: traefik-ingress-controller\n name: traefik-ingress-controller\n spec:\n serviceAccountName: traefik-ingress-controller\n terminationGracePeriodSeconds: 60\n volumes:\n - name: config\n configMap:\n name: traefik-ingress-controller\n containers:\n - image: traefik:v1.7.3\n name: traefik-ingress-controller\n livenessProbe:\n tcpSocket:\n port: 80\n failureThreshold: 3\n initialDelaySeconds: 10\n periodSeconds: 10\n successThreshold: 1\n timeoutSeconds: 2\n volumeMounts:\n - mountPath: /config\n name: config\n resources:\n limits:\n memory: 512Mi\n requests:\n memory: 128Mi\n ports:\n - containerPort: 80\n - containerPort: 8080\n - containerPort: 443\n args:\n - --configfile=/config/traefik.toml\n nodeSelector:\n kubernetes.io/hostname: minikube\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: traefik-ingress-controller\n namespace: kube-system\nspec:\n type: NodePort\n ports:\n - port: 80\n name: http\n targetPort: 80\n nodePort: 32300\n selector:\n k8s-app: traefik-ingress-controller\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-ui\n namespace: haystack-apps\n annotations:\n kubernetes.io/ingress.class: traefik\nspec:\n rules:\n - host: haystack.local\n http:\n paths:\n - path: /\n backend:\n serviceName: haystack-ui\n servicePort: 80\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-http-span-collector\n namespace: haystack-apps\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefix\nspec:\n rules:\n - host: haystack.local\n http:\n paths:\n - path: /span\n backend:\n serviceName: http-span-collector\n servicePort: 80\n---\n\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-infrastructure", "kafka", "zookeeper" ], "outputs": { "zookeeper_service_name": { "sensitive": false, "type": "string", "value": "zookeeper" }, "zookeeper_service_port": { "sensitive": false, "type": "string", "value": "2181" } }, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.container_port", "local.deployment_yaml_file_path", "local.image", "local.service_port" ], "primary": { "id": "ca9681ff9503b6b5042ba1f104190947c5ffd45b800723f26625ff2edaa344e8", "attributes": { "id": "ca9681ff9503b6b5042ba1f104190947c5ffd45b800723f26625ff2edaa344e8", "rendered": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: zookeeper\n name: zookeeper\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: zookeeper\n template:\n metadata:\n labels:\n k8s-app: zookeeper\n spec:\n containers:\n - name: zookeeper\n image: zookeeper:3.4.12\n resources:\n limits:\n memory: 1224Mi\n requests:\n cpu: 100m\n memory: 1224\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: zookeeper\n name: zookeeper\n namespace: haystack-apps\nspec:\n ports:\n - port: 2181\n targetPort: 2181\n selector:\n k8s-app: zookeeper", "template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_limit}\n memory: ${memory_limit}\n nodeSelector:\n ${node_selecter_label}\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}", "vars.%": "9", "vars.app_name": "zookeeper", "vars.container_port": "2181", "vars.cpu_limit": "100m", "vars.image": "zookeeper:3.4.12", "vars.memory_limit": "1224", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "2181" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml" ], "primary": { "id": "3786221622711630242", "attributes": { "id": "3786221622711630242", "triggers.%": "1", "triggers.template": "kind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: zookeeper\n name: zookeeper\n namespace: haystack-apps\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: zookeeper\n template:\n metadata:\n labels:\n k8s-app: zookeeper\n spec:\n containers:\n - name: zookeeper\n image: zookeeper:3.4.12\n resources:\n limits:\n memory: 1224Mi\n requests:\n cpu: 100m\n memory: 1224\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: zookeeper\n name: zookeeper\n namespace: haystack-apps\nspec:\n ports:\n - port: 2181\n targetPort: 2181\n selector:\n k8s-app: zookeeper" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "alerting-addon", "kubewatch-addon" ], "outputs": {}, "resources": { "data.template_file.kubewatch_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "8cf3169e9776c55aec841f6ede65f48324c8189af4567aa7fbf343f1113a85ff", "attributes": { "id": "8cf3169e9776c55aec841f6ede65f48324c8189af4567aa7fbf343f1113a85ff", "rendered": "kind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: kubewatch\nrules:\n - apiGroups:\n - \"\"\n resources:\n - pods\n - services\n - endpoints\n - secrets\n verbs:\n - get\n - list\n - watch\n - apiGroups:\n - extensions\n resources:\n - ingresses\n verbs:\n - get\n - list\n - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: kubewatch \nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: kubewatch\nsubjects:\n- kind: ServiceAccount\n name: kubewatch\n namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: kubewatch\n namespace: kube-system\n---\nkind: Secret\napiVersion: v1\nmetadata:\n name: kubewatch\n namespace: kube-system\ntype: Opaque\ndata:\n .kubewatch.yaml: \n---\napiVersion: v1\nkind: Pod\nmetadata:\n name: kubewatch\n namespace: kube-system\nspec:\n serviceAccountName: kubewatch \n containers:\n - image: tuna/kubewatch:v0.0.1\n imagePullPolicy: Always\n name: kubewatch\n volumeMounts:\n - name: config-volume\n mountPath: /root\n restartPolicy: Always\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n secret:\n secretName: kubewatch\n\n", "template": "kind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: kubewatch\nrules:\n - apiGroups:\n - \"\"\n resources:\n - pods\n - services\n - endpoints\n - secrets\n verbs:\n - get\n - list\n - watch\n - apiGroups:\n - extensions\n resources:\n - ingresses\n verbs:\n - get\n - list\n - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: kubewatch \nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: kubewatch\nsubjects:\n- kind: ServiceAccount\n name: kubewatch\n namespace: kube-system\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: kubewatch\n namespace: kube-system\n---\nkind: Secret\napiVersion: v1\nmetadata:\n name: kubewatch\n namespace: kube-system\ntype: Opaque\ndata:\n .kubewatch.yaml: ${kubewatch_config_yaml_base64}\n---\napiVersion: v1\nkind: Pod\nmetadata:\n name: kubewatch\n namespace: kube-system\nspec:\n serviceAccountName: kubewatch \n containers:\n - image: ${kubewatch_image}\n imagePullPolicy: Always\n name: kubewatch\n volumeMounts:\n - name: config-volume\n mountPath: /root\n restartPolicy: Always\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n secret:\n secretName: kubewatch\n\n", "vars.%": "3", "vars.kubewatch_config_yaml_base64": "", "vars.kubewatch_image": "tuna/kubewatch:v0.0.1", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "logging-addons", "curator-addon" ], "outputs": {}, "resources": { "data.template_file.curator_cron_job": { "type": "template_file", "depends_on": [], "primary": { "id": "7784cb192872e23a3c3ebd7db369815fda388b13ee2fab164ee8867ca147abfb", "attributes": { "id": "7784cb192872e23a3c3ebd7db369815fda388b13ee2fab164ee8867ca147abfb", "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-logs\n namespace: kube-system\n labels:\n app: curator-es-logs\ndata:\n curator.yml: |-\n client:\n hosts:\n - elasticsearch-logging\n port: 9200\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: INFO\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: logstash-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y.%m.%d\"\n unit: days\n unit_count: 2\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-logs\n namespace: kube-system\n\nspec:\n schedule: \"0 0 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-logs\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config\n configMap:\n name: curator-es-logs\n", "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-logs\n namespace: kube-system\n labels:\n app: curator-es-logs\ndata:\n curator.yml: |-\n client:\n hosts:\n - ${elasticsearch_host}\n port: 9200\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: INFO\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: logstash-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y.%m.%d\"\n unit: days\n unit_count: 2\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-logs\n namespace: kube-system\n\nspec:\n schedule: \"0 0 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-logs\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config\n configMap:\n name: curator-es-logs\n", "vars.%": "2", "vars.elasticsearch_host": "elasticsearch-logging", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "logging-addons", "elasticsearch-addon" ], "outputs": { "host": { "sensitive": false, "type": "string", "value": "elasticsearch-logging" }, "http_endpoint": { "sensitive": false, "type": "string", "value": "http://elasticsearch-logging:9200" }, "port": { "sensitive": false, "type": "string", "value": "9200" } }, "resources": { "data.template_file.elasticsearch_addon_config": { "type": "template_file", "depends_on": [ "local.elasticsearch-name" ], "primary": { "id": "91306bf7b3b30a4b36acc5c0ff33e76605742cdcf339a4597b71a4a9e644d219", "attributes": { "id": "91306bf7b3b30a4b36acc5c0ff33e76605742cdcf339a4597b71a4a9e644d219", "rendered": "# Elasticsearch deployment itself\napiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n name: elasticsearch-logging\n namespace: kube-system\n labels:\n k8s-app: elasticsearch-logging\n version: v5.6.5\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\nspec:\n serviceName: elasticsearch-logging\n replicas: 1\n selector:\n matchLabels:\n k8s-app: elasticsearch-logging\n version: v5.6.5\n template:\n metadata:\n labels:\n k8s-app: elasticsearch-logging\n version: v5.6.5\n kubernetes.io/cluster-service: \"true\"\n spec:\n containers:\n - image: gcr.io/google-containers/elasticsearch:v5.6.4\n name: elasticsearch-logging\n resources:\n # need more cpu upon initialization, therefore burstable class\n limits:\n memory: 1024Mi\n ports:\n - containerPort: 9200\n name: db\n protocol: TCP\n - containerPort: 9300\n name: transport\n protocol: TCP\n volumeMounts:\n - name: elasticsearch-logging\n mountPath: /data\n env:\n - name: \"ES_JAVA_OPTS\"\n value: \"-Xms1024m -Xmx1024m\"\n - name: \"MINIMUM_MASTER_NODES\"\n value: \"1\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n initContainers:\n - image: alpine:3.6\n command: [\"/sbin/sysctl\", \"-w\", \"vm.max_map_count=262144\"]\n name: elasticsearch-logging-init\n securityContext:\n privileged: true\n volumeClaimTemplates:\n - metadata:\n name: elasticsearch-logging\n annotations:\n volume.beta.kubernetes.io/storage-class: \"default\"\n spec:\n storageClassName: \"default\"\n accessModes: [\"ReadWriteOnce\"]\n resources:\n requests:\n storage: \"100Mi\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: elasticsearch-logging\n namespace: kube-system\n labels:\n k8s-app: elasticsearch-logging\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\n kubernetes.io/name: \"Elasticsearch\"\nspec:\n ports:\n - port: 9200\n protocol: TCP\n targetPort: db\n selector:\n k8s-app: elasticsearch-logging\n", "template": "# Elasticsearch deployment itself\napiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n name: ${elasticsearch-name}\n namespace: kube-system\n labels:\n k8s-app: ${elasticsearch-name}\n version: v5.6.5\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\nspec:\n serviceName: ${elasticsearch-name}\n replicas: ${minimum_masters}\n selector:\n matchLabels:\n k8s-app: ${elasticsearch-name}\n version: v5.6.5\n template:\n metadata:\n labels:\n k8s-app: ${elasticsearch-name}\n version: v5.6.5\n kubernetes.io/cluster-service: \"true\"\n spec:\n containers:\n - image: gcr.io/google-containers/elasticsearch:v5.6.4\n name: ${elasticsearch-name}\n resources:\n # need more cpu upon initialization, therefore burstable class\n limits:\n memory: ${heap_memory_in_mb}Mi\n ports:\n - containerPort: 9200\n name: db\n protocol: TCP\n - containerPort: 9300\n name: transport\n protocol: TCP\n volumeMounts:\n - name: ${elasticsearch-name}\n mountPath: /data\n env:\n - name: \"ES_JAVA_OPTS\"\n value: \"-Xms${heap_memory_in_mb}m -Xmx${heap_memory_in_mb}m\"\n - name: \"MINIMUM_MASTER_NODES\"\n value: \"${minimum_masters}\"\n nodeSelector:\n ${node_selecter_label}\n initContainers:\n - image: alpine:3.6\n command: [\"/sbin/sysctl\", \"-w\", \"vm.max_map_count=262144\"]\n name: ${elasticsearch-name}-init\n securityContext:\n privileged: true\n volumeClaimTemplates:\n - metadata:\n name: ${elasticsearch-name}\n annotations:\n volume.beta.kubernetes.io/storage-class: \"${storage_class}\"\n spec:\n storageClassName: \"${storage_class}\"\n accessModes: [\"ReadWriteOnce\"]\n resources:\n requests:\n storage: \"${storage_volume}\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: ${elasticsearch-name}\n namespace: kube-system\n labels:\n k8s-app: ${elasticsearch-name}\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\n kubernetes.io/name: \"Elasticsearch\"\nspec:\n ports:\n - port: 9200\n protocol: TCP\n targetPort: db\n selector:\n k8s-app: ${elasticsearch-name}\n", "vars.%": "6", "vars.elasticsearch-name": "elasticsearch-logging", "vars.heap_memory_in_mb": "1024", "vars.minimum_masters": "1", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.storage_class": "default", "vars.storage_volume": "100Mi" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "logging-addons", "fluentd-addon" ], "outputs": {}, "resources": { "data.template_file.fluentd_cluster_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "2ab32198b909b7ab8597255f79dbae7fbbc397afcb44f22aefb679061a241bf1", "attributes": { "id": "2ab32198b909b7ab8597255f79dbae7fbbc397afcb44f22aefb679061a241bf1", "rendered": "apiVersion: v1\nkind: ConfigMap\ndata:\n containers.input.conf: |-\n \u003csource\u003e\n type tail\n path /var/log/containers/*.log\n pos_file /var/log/es-containers.log.pos\n time_format %Y-%m-%dT%H:%M:%S.%NZ\n tag kubernetes.*\n read_from_head true\n format multi_format\n \u003cpattern\u003e\n format json\n time_key time\n time_format %Y-%m-%dT%H:%M:%S.%NZ\n \u003c/pattern\u003e\n \u003cpattern\u003e\n format /^(?\u003ctime\u003e.+) (?\u003cstream\u003estdout|stderr) [^ ]* (?\u003clog\u003e.*)$/\n time_format %Y-%m-%dT%H:%M:%S.%N%:z\n \u003c/pattern\u003e\n \u003c/source\u003e\n output.conf: |-\n # Enriches records with Kubernetes metadata\n \u003cfilter kubernetes.**\u003e\n type kubernetes_metadata\n \u003c/filter\u003e\n \u003cmatch kubernetes.var.log.containers.**fluentd**.log\u003e\n @type null\n \u003c/match\u003e\n \u003cmatch kubernetes.var.log.containers.**kube-system**.log\u003e\n @type null\n \u003c/match\u003e\n \u003cmatch kubernetes.**\u003e\n type elasticsearch\n log_level info\n include_tag_key true\n host elasticsearch-logging\n port 9200\n logstash_format true\n # Set the chunk limits.\n buffer_chunk_limit 2M\n buffer_queue_limit 8\n flush_interval 5s\n # Never wait longer than 5 minutes between retries.\n max_retry_wait 30\n # Disable the limit on the number of retries (retry forever).\n disable_retry_limit\n # Use multiple threads for processing.\n num_threads 2\n \u003c/match\u003e\nmetadata:\n name: fluentd-es-config\n namespace: kube-system\n labels:\n addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: fluentd\n namespace: kube-system\n labels:\n k8s-app: fluentd\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\n kubernetes.io/name: \"Elasticsearch\"\nspec:\n ports:\n - port: 9200\n protocol: TCP\n targetPort: db\n selector:\n k8s-app: fluentd\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: fluentd\nrules:\n- apiGroups: [\"\"] # \"\" indicates the core API group\n resources: [\"pods\", \"namespaces\"]\n verbs: [\"get\", \"watch\", \"list\"]\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: fluentd\n namespace: kube-system\n---\n# This role binding allows \"system:serviceaccount:logs:default\" to read pods in the \"default\" namespace.\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: fluentd\nsubjects:\n- kind: ServiceAccount\n name: fluentd\n namespace: kube-system\nroleRef:\n kind: ClusterRole\n name: fluentd\n apiGroup: rbac.authorization.k8s.io\n---\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n labels:\n k8s-app: fluentd-logging\n kubernetes.io/cluster-service: \"true\"\n name: fluentd-elasticsearch\n namespace: kube-system\nspec:\n selector:\n matchLabels:\n k8s-app: fluentd-logging\n kubernetes.io/cluster-service: \"true\"\n template:\n metadata:\n annotations:\n scheduler.alpha.kubernetes.io/critical-pod: \"\"\n creationTimestamp: null\n labels:\n k8s-app: fluentd-logging\n kubernetes.io/cluster-service: \"true\"\n name: fluentd-elasticsearch\n namespace: kube-system\n spec:\n serviceAccount: fluentd\n hostNetwork: false\n containers:\n - env:\n - name: FLUENTD_ARGS\n value: --no-supervisor -q\n image: gcr.io/google-containers/fluentd-elasticsearch:v2.0.2\n imagePullPolicy: IfNotPresent\n name: fluentd-elasticsearch\n resources:\n limits:\n memory: 500Mi\n requests:\n cpu: 100m\n memory: 200Mi\n volumeMounts:\n - mountPath: /var/log\n name: varlog\n - mountPath: /mnt/sda1/var/lib/docker/containers\n name: varlibdockercontainers\n readOnly: true\n - name: varlibdocker\n mountPath: /var/lib/docker/\n readOnly: true\n - name: config-volume\n mountPath: /etc/fluent/config.d\n restartPolicy: Always\n volumes:\n - name: varlibdocker\n hostPath:\n path: /var/lib/docker/\n - hostPath:\n path: /var/log\n name: varlog\n - hostPath:\n path: /mnt/sda1/var/lib/docker/containers\n name: varlibdockercontainers\n - name: config-volume\n configMap:\n name: fluentd-es-config\n", "template": "apiVersion: v1\nkind: ConfigMap\ndata:\n containers.input.conf: |-\n \u003csource\u003e\n type tail\n path /var/log/containers/*.log\n pos_file /var/log/es-containers.log.pos\n time_format %Y-%m-%dT%H:%M:%S.%NZ\n tag kubernetes.*\n read_from_head true\n format multi_format\n \u003cpattern\u003e\n format json\n time_key time\n time_format %Y-%m-%dT%H:%M:%S.%NZ\n \u003c/pattern\u003e\n \u003cpattern\u003e\n format /^(?\u003ctime\u003e.+) (?\u003cstream\u003estdout|stderr) [^ ]* (?\u003clog\u003e.*)$/\n time_format %Y-%m-%dT%H:%M:%S.%N%:z\n \u003c/pattern\u003e\n \u003c/source\u003e\n output.conf: |-\n # Enriches records with Kubernetes metadata\n \u003cfilter kubernetes.**\u003e\n type kubernetes_metadata\n \u003c/filter\u003e\n \u003cmatch kubernetes.var.log.containers.**fluentd**.log\u003e\n @type null\n \u003c/match\u003e\n \u003cmatch kubernetes.var.log.containers.**kube-system**.log\u003e\n @type null\n \u003c/match\u003e\n \u003cmatch kubernetes.**\u003e\n type elasticsearch\n log_level info\n include_tag_key true\n host ${elasticsearch_host}\n port ${elasticsearch_port}\n logstash_format true\n # Set the chunk limits.\n buffer_chunk_limit 2M\n buffer_queue_limit 8\n flush_interval 5s\n # Never wait longer than 5 minutes between retries.\n max_retry_wait 30\n # Disable the limit on the number of retries (retry forever).\n disable_retry_limit\n # Use multiple threads for processing.\n num_threads 2\n \u003c/match\u003e\nmetadata:\n name: fluentd-es-config\n namespace: kube-system\n labels:\n addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: fluentd\n namespace: kube-system\n labels:\n k8s-app: fluentd\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\n kubernetes.io/name: \"Elasticsearch\"\nspec:\n ports:\n - port: 9200\n protocol: TCP\n targetPort: db\n selector:\n k8s-app: fluentd\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: fluentd\nrules:\n- apiGroups: [\"\"] # \"\" indicates the core API group\n resources: [\"pods\", \"namespaces\"]\n verbs: [\"get\", \"watch\", \"list\"]\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: fluentd\n namespace: kube-system\n---\n# This role binding allows \"system:serviceaccount:logs:default\" to read pods in the \"default\" namespace.\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n name: fluentd\nsubjects:\n- kind: ServiceAccount\n name: fluentd\n namespace: kube-system\nroleRef:\n kind: ClusterRole\n name: fluentd\n apiGroup: rbac.authorization.k8s.io\n---\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n labels:\n k8s-app: fluentd-logging\n kubernetes.io/cluster-service: \"true\"\n name: fluentd-elasticsearch\n namespace: kube-system\nspec:\n selector:\n matchLabels:\n k8s-app: fluentd-logging\n kubernetes.io/cluster-service: \"true\"\n template:\n metadata:\n annotations:\n scheduler.alpha.kubernetes.io/critical-pod: \"\"\n creationTimestamp: null\n labels:\n k8s-app: fluentd-logging\n kubernetes.io/cluster-service: \"true\"\n name: fluentd-elasticsearch\n namespace: kube-system\n spec:\n serviceAccount: fluentd\n hostNetwork: false\n containers:\n - env:\n - name: FLUENTD_ARGS\n value: --no-supervisor -q\n image: ${fluentd_image}\n imagePullPolicy: IfNotPresent\n name: fluentd-elasticsearch\n resources:\n limits:\n memory: 500Mi\n requests:\n cpu: 100m\n memory: 200Mi\n volumeMounts:\n - mountPath: /var/log\n name: varlog\n - mountPath: ${container_log_path}\n name: varlibdockercontainers\n readOnly: true\n - name: varlibdocker\n mountPath: /var/lib/docker/\n readOnly: true\n - name: config-volume\n mountPath: /etc/fluent/config.d\n restartPolicy: Always\n volumes:\n - name: varlibdocker\n hostPath:\n path: /var/lib/docker/\n - hostPath:\n path: /var/log\n name: varlog\n - hostPath:\n path: ${container_log_path}\n name: varlibdockercontainers\n - name: config-volume\n configMap:\n name: fluentd-es-config\n", "vars.%": "4", "vars.container_log_path": "/mnt/sda1/var/lib/docker/containers", "vars.elasticsearch_host": "elasticsearch-logging", "vars.elasticsearch_port": "9200", "vars.fluentd_image": "gcr.io/google-containers/fluentd-elasticsearch:v2.0.2" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "logging-addons", "kibana-addon" ], "outputs": {}, "resources": { "data.template_file.kibana_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "553481c4bd01b68b37bcbd369c333e086c8e217772966a5226a4c6e3010238b3", "attributes": { "id": "553481c4bd01b68b37bcbd369c333e086c8e217772966a5226a4c6e3010238b3", "rendered": "apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n name: kibana-logging\n namespace: kube-system\n labels:\n k8s-app: kibana-logging\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: kibana-logging\n template:\n metadata:\n labels:\n k8s-app: kibana-logging\n spec:\n containers:\n - name: kibana-logging\n image: docker.elastic.co/kibana/kibana:5.6.5\n resources:\n # need more cpu upon initialization, therefore burstable class\n limits:\n cpu: 1000m\n requests:\n cpu: 100m\n env:\n - name: ELASTICSEARCH_URL\n value: http://elasticsearch-logging:9200\n - name: XPACK_MONITORING_ENABLED\n value: \"false\"\n - name: XPACK_SECURITY_ENABLED\n value: \"false\"\n ports:\n - containerPort: 5601\n name: ui\n protocol: TCP\n nodeSelector:\n kubernetes.io/hostname: minikube\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: kibana-logging\n namespace: kube-system\n labels:\n k8s-app: kibana-logging\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\n kubernetes.io/name: \"Kibana\"\nspec:\n ports:\n - port: 5601\n protocol: TCP\n targetPort: ui\n selector:\n k8s-app: kibana-logging\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-es\n namespace: kube-system\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefixStrip\nspec:\n rules:\n - host: logs.haystack.local\n http:\n paths:\n - path: /\n backend:\n serviceName: kibana-logging\n servicePort: 5601\n\n", "template": "apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n name: kibana-logging\n namespace: kube-system\n labels:\n k8s-app: kibana-logging\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: kibana-logging\n template:\n metadata:\n labels:\n k8s-app: kibana-logging\n spec:\n containers:\n - name: kibana-logging\n image: docker.elastic.co/kibana/kibana:5.6.5\n resources:\n # need more cpu upon initialization, therefore burstable class\n limits:\n cpu: 1000m\n requests:\n cpu: 100m\n env:\n - name: ELASTICSEARCH_URL\n value: ${elasticsearch_http_endpoint}\n - name: XPACK_MONITORING_ENABLED\n value: \"false\"\n - name: XPACK_SECURITY_ENABLED\n value: \"false\"\n ports:\n - containerPort: 5601\n name: ui\n protocol: TCP\n nodeSelector:\n ${node_selecter_label}\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: kibana-logging\n namespace: kube-system\n labels:\n k8s-app: kibana-logging\n kubernetes.io/cluster-service: \"true\"\n addonmanager.kubernetes.io/mode: Reconcile\n kubernetes.io/name: \"Kibana\"\nspec:\n ports:\n - port: 5601\n protocol: TCP\n targetPort: ui\n selector:\n k8s-app: kibana-logging\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-es\n namespace: kube-system\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefixStrip\nspec:\n rules:\n - host: ${logs_cname}\n http:\n paths:\n - path: /\n backend:\n serviceName: kibana-logging\n servicePort: 5601\n\n", "vars.%": "3", "vars.elasticsearch_http_endpoint": "http://elasticsearch-logging:9200", "vars.logs_cname": "logs.haystack.local", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "monitoring-addons", "dashboard-addon" ], "outputs": {}, "resources": { "data.template_file.dashboard_cluster_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "b3f0d85e54bcf439445f46f684b6c387c4fd204f204fd56cc3e9bbaef19f6989", "attributes": { "id": "b3f0d85e54bcf439445f46f684b6c387c4fd204f204fd56cc3e9bbaef19f6989", "rendered": "\n# ------------------- Dashboard Service Account ------------------- #\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n name: haystack-kubernetes-dashboard\n namespace: kube-system\n\n---\n# ------------------- Dashboard Role \u0026 Role Binding ------------------- #\n\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: haystack-kubernetes-dashboard-minimal\n namespace: kube-system\nrules:\n # Allow Dashboard to create 'haystack-kubernetes-dashboard-key-holder' secret.\n- apiGroups: [\"\"]\n resources: [\"secrets\"]\n verbs: [\"create\"]\n # Allow Dashboard to create 'haystack-kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n resources: [\"configmaps\"]\n verbs: [\"create\"]\n # Allow Dashboard to get, update and delete Dashboard exclusive secrets.\n- apiGroups: [\"\"]\n resources: [\"secrets\"]\n resourceNames: [\"haystack-kubernetes-dashboard-key-holder\"]\n verbs: [\"get\", \"update\", \"delete\"]\n # Allow Dashboard to get and update 'haystack-kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n resources: [\"configmaps\"]\n resourceNames: [\"haystack-kubernetes-dashboard-settings\"]\n verbs: [\"get\", \"update\"]\n # Allow Dashboard to get metrics from heapster.\n- apiGroups: [\"\"]\n resources: [\"services\"]\n resourceNames: [\"heapster\"]\n verbs: [\"proxy\"]\n- apiGroups: [\"\"]\n resources: [\"services/proxy\"]\n resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\"]\n verbs: [\"get\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: haystack-kubernetes-dashboard-minimal\n namespace: kube-system\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: Role\n name: haystack-kubernetes-dashboard-minimal\nsubjects:\n- kind: ServiceAccount\n name: haystack-kubernetes-dashboard\n namespace: kube-system\n\n---\n# ------------------- Dashboard Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n name: haystack-kubernetes-dashboard\n namespace: kube-system\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: haystack-kubernetes-dashboard\n template:\n metadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n spec:\n containers:\n - name: haystack-kubernetes-dashboard\n image: k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.2\n ports:\n - containerPort: 9090\n protocol: TCP\n args:\n # Uncomment the following line to manually specify Kubernetes API server Host\n # If not specified, Dashboard will attempt to auto discover the API server and connect\n # to it. Uncomment only if the default does not work.\n # - --apiserver-host=http://my-address:port\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /tmp\n name: tmp-volume\n livenessProbe:\n httpGet:\n path: /\n port: 9090\n initialDelaySeconds: 30\n timeoutSeconds: 30\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: tmp-volume\n emptyDir: {}\n serviceAccountName: haystack-kubernetes-dashboard\n # Comment the following tolerations if Dashboard must not be deployed on master\n tolerations:\n - key: node-role.kubernetes.io/master\n effect: NoSchedule\n\n---\n# ------------------- Dashboard Service ------------------- #\n\nkind: Service\napiVersion: v1\nmetadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n name: haystack-kubernetes-dashboard\n namespace: kube-system\nspec:\n ports:\n - port: 80\n targetPort: 9090\n selector:\n k8s-app: haystack-kubernetes-dashboard\n\n---\n# ------------------- Ingress Rule ------------------------ #\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-kubernetes-dashboard\n namespace: kube-system\n annotations:\n kubernetes.io/ingress.class: traefik\nspec:\n rules:\n - host: k8s.haystack.local\n http:\n paths:\n - path: /\n backend:\n serviceName: haystack-kubernetes-dashboard\n servicePort: 80\n", "template": "\n# ------------------- Dashboard Service Account ------------------- #\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n name: haystack-kubernetes-dashboard\n namespace: kube-system\n\n---\n# ------------------- Dashboard Role \u0026 Role Binding ------------------- #\n\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n name: haystack-kubernetes-dashboard-minimal\n namespace: kube-system\nrules:\n # Allow Dashboard to create 'haystack-kubernetes-dashboard-key-holder' secret.\n- apiGroups: [\"\"]\n resources: [\"secrets\"]\n verbs: [\"create\"]\n # Allow Dashboard to create 'haystack-kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n resources: [\"configmaps\"]\n verbs: [\"create\"]\n # Allow Dashboard to get, update and delete Dashboard exclusive secrets.\n- apiGroups: [\"\"]\n resources: [\"secrets\"]\n resourceNames: [\"haystack-kubernetes-dashboard-key-holder\"]\n verbs: [\"get\", \"update\", \"delete\"]\n # Allow Dashboard to get and update 'haystack-kubernetes-dashboard-settings' config map.\n- apiGroups: [\"\"]\n resources: [\"configmaps\"]\n resourceNames: [\"haystack-kubernetes-dashboard-settings\"]\n verbs: [\"get\", \"update\"]\n # Allow Dashboard to get metrics from heapster.\n- apiGroups: [\"\"]\n resources: [\"services\"]\n resourceNames: [\"heapster\"]\n verbs: [\"proxy\"]\n- apiGroups: [\"\"]\n resources: [\"services/proxy\"]\n resourceNames: [\"heapster\", \"http:heapster:\", \"https:heapster:\"]\n verbs: [\"get\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n name: haystack-kubernetes-dashboard-minimal\n namespace: kube-system\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: Role\n name: haystack-kubernetes-dashboard-minimal\nsubjects:\n- kind: ServiceAccount\n name: haystack-kubernetes-dashboard\n namespace: kube-system\n\n---\n# ------------------- Dashboard Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n name: haystack-kubernetes-dashboard\n namespace: kube-system\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: haystack-kubernetes-dashboard\n template:\n metadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n spec:\n containers:\n - name: haystack-kubernetes-dashboard\n image: ${dashboard_image}\n ports:\n - containerPort: 9090\n protocol: TCP\n args:\n # Uncomment the following line to manually specify Kubernetes API server Host\n # If not specified, Dashboard will attempt to auto discover the API server and connect\n # to it. Uncomment only if the default does not work.\n # - --apiserver-host=http://my-address:port\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /tmp\n name: tmp-volume\n livenessProbe:\n httpGet:\n path: /\n port: 9090\n initialDelaySeconds: 30\n timeoutSeconds: 30\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: tmp-volume\n emptyDir: {}\n serviceAccountName: haystack-kubernetes-dashboard\n # Comment the following tolerations if Dashboard must not be deployed on master\n tolerations:\n - key: node-role.kubernetes.io/master\n effect: NoSchedule\n\n---\n# ------------------- Dashboard Service ------------------- #\n\nkind: Service\napiVersion: v1\nmetadata:\n labels:\n k8s-app: haystack-kubernetes-dashboard\n name: haystack-kubernetes-dashboard\n namespace: kube-system\nspec:\n ports:\n - port: 80\n targetPort: 9090\n selector:\n k8s-app: haystack-kubernetes-dashboard\n\n---\n# ------------------- Ingress Rule ------------------------ #\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-kubernetes-dashboard\n namespace: kube-system\n annotations:\n kubernetes.io/ingress.class: traefik\nspec:\n rules:\n - host: ${dashboard_cname}\n http:\n paths:\n - path: /\n backend:\n serviceName: haystack-kubernetes-dashboard\n servicePort: 80\n", "vars.%": "3", "vars.dashboard_cname": "k8s.haystack.local", "vars.dashboard_image": "k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.2", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "monitoring-addons", "grafana-addon" ], "outputs": {}, "resources": { "data.template_file.grafana_cluster_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "f173126bad04a4299b9a2a456dfc479ff0f36ba7d3976db3c6c1c022421a482a", "attributes": { "id": "f173126bad04a4299b9a2a456dfc479ff0f36ba7d3976db3c6c1c022421a482a", "rendered": "apiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n name: monitoring-grafana\n namespace: kube-system\nspec:\n replicas: 1\n serviceName: monitoring-grafana\n template:\n metadata:\n labels:\n task: monitoring\n k8s-app: grafana\n spec:\n containers:\n - name: grafana\n image: gcr.io/google_containers/heapster-grafana-amd64:v4.4.3\n resources:\n limits:\n cpu: 100m\n memory: 100Mi\n requests:\n cpu: 100m\n memory: 100Mi\n ports:\n - containerPort: 3000\n protocol: TCP\n volumeMounts:\n - mountPath: /var\n name: grafana-persistent-storage\n - mountPath: /etc/ssl/certs\n name: etc-ssl-certs\n env:\n - name: INFLUXDB_HOST\n value: monitoring-influxdb\n - name: GF_SERVER_HTTP_PORT\n value: \"3000\"\n - name: GF_SERVER_ROOT_URL\n value: \"https://metrics.haystack.local\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: etc-ssl-certs\n hostPath:\n path: /etc/ssl/certs\n volumeClaimTemplates:\n - metadata:\n name: grafana-persistent-storage\n annotations:\n volume.beta.kubernetes.io/storage-class: \"default\"\n spec:\n storageClassName: \"default\"\n accessModes: [\"ReadWriteOnce\"]\n resources:\n requests:\n storage: \"100Mi\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n kubernetes.io/cluster-service: \"true\"\n kubernetes.io/name: monitoring-grafana\n name: monitoring-grafana\n namespace: kube-system\nspec:\n ports:\n - port: 80\n targetPort: 3000\n selector:\n k8s-app: grafana\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-grafana\n namespace: kube-system\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefixStrip\nspec:\n rules:\n - host: metrics.haystack.local\n http:\n paths:\n - path: /\n backend:\n serviceName: monitoring-grafana\n servicePort: 80\n", "template": "apiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n name: monitoring-grafana\n namespace: kube-system\nspec:\n replicas: 1\n serviceName: monitoring-grafana\n template:\n metadata:\n labels:\n task: monitoring\n k8s-app: grafana\n spec:\n containers:\n - name: grafana\n image: ${grafana_image}\n resources:\n limits:\n cpu: 100m\n memory: 100Mi\n requests:\n cpu: 100m\n memory: 100Mi\n ports:\n - containerPort: 3000\n protocol: TCP\n volumeMounts:\n - mountPath: /var\n name: grafana-persistent-storage\n - mountPath: /etc/ssl/certs\n name: etc-ssl-certs\n env:\n - name: INFLUXDB_HOST\n value: monitoring-influxdb\n - name: GF_SERVER_HTTP_PORT\n value: \"3000\"\n - name: GF_SERVER_ROOT_URL\n value: \"https://${metrics_cname}\"\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: etc-ssl-certs\n hostPath:\n path: /etc/ssl/certs\n volumeClaimTemplates:\n - metadata:\n name: grafana-persistent-storage\n annotations:\n volume.beta.kubernetes.io/storage-class: \"${grafana_storage_class}\"\n spec:\n storageClassName: \"${grafana_storage_class}\"\n accessModes: [\"ReadWriteOnce\"]\n resources:\n requests:\n storage: \"${grafana_storage}\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n kubernetes.io/cluster-service: \"true\"\n kubernetes.io/name: monitoring-grafana\n name: monitoring-grafana\n namespace: kube-system\nspec:\n ports:\n - port: 80\n targetPort: 3000\n selector:\n k8s-app: grafana\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: traefik-haystack-grafana\n namespace: kube-system\n annotations:\n kubernetes.io/ingress.class: traefik\n traefik.frontend.rule.type: PathPrefixStrip\nspec:\n rules:\n - host: ${metrics_cname}\n http:\n paths:\n - path: /\n backend:\n serviceName: monitoring-grafana\n servicePort: 80\n", "vars.%": "5", "vars.grafana_image": "gcr.io/google_containers/heapster-grafana-amd64:v4.4.3", "vars.grafana_storage": "100Mi", "vars.grafana_storage_class": "default", "vars.metrics_cname": "metrics.haystack.local", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "monitoring-addons", "heapster-addon" ], "outputs": {}, "resources": { "data.template_file.heapster_cluster_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "9d553569dedf323429d1e25c16817deff46142e4428c752b6eb211041dda4146", "attributes": { "id": "9d553569dedf323429d1e25c16817deff46142e4428c752b6eb211041dda4146", "rendered": "apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n name: heapster\n namespace: kube-system\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\n k8s-app: heapster\n kubernetes.io/cluster-service: \"true\"\n version: v1.6.0\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: heapster\n version: v1.6.0\n template:\n metadata:\n labels:\n k8s-app: heapster\n version: v1.6.0\n annotations:\n scheduler.alpha.kubernetes.io/critical-pod: \"\"\n scheduler.alpha.kubernetes.io/tolerations: \"[{\\\"key\\\":\\\"CriticalAddonsOnly\\\", \\\"operator\\\":\\\"Exists\\\"}]\"\n spec:\n serviceAccountName: heapster\n containers:\n - image: gcr.io/google_containers/heapster-amd64:v1.5.0\n name: heapster\n livenessProbe:\n httpGet:\n path: /healthz\n port: 8082\n scheme: HTTP\n initialDelaySeconds: 180\n timeoutSeconds: 5\n resources:\n # keep request = limit to keep this container in guaranteed class\n limits:\n cpu: 100m\n memory: 300Mi\n requests:\n cpu: 100m\n memory: 300Mi\n command:\n - /heapster\n - --source=kubernetes:https://kubernetes.default\n - --sink=influxdb:http://monitoring-influxdb.kube-system.svc:8086\n nodeSelector:\n kubernetes.io/hostname: minikube\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: heapster\n namespace: kube-system\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\n kubernetes.io/name: \"Heapster\"\n kubernetes.io/cluster-service: \"true\"\nspec:\n ports:\n - port: 80\n targetPort: 8082\n selector:\n k8s-app: heapster\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: heapster\n namespace: kube-system\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n name: heapster\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: system:heapster\nsubjects:\n- kind: ServiceAccount\n name: heapster\n namespace: kube-system", "template": "apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n name: heapster\n namespace: kube-system\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\n k8s-app: heapster\n kubernetes.io/cluster-service: \"true\"\n version: v1.6.0\nspec:\n replicas: 1\n selector:\n matchLabels:\n k8s-app: heapster\n version: v1.6.0\n template:\n metadata:\n labels:\n k8s-app: heapster\n version: v1.6.0\n annotations:\n scheduler.alpha.kubernetes.io/critical-pod: \"\"\n scheduler.alpha.kubernetes.io/tolerations: \"[{\\\"key\\\":\\\"CriticalAddonsOnly\\\", \\\"operator\\\":\\\"Exists\\\"}]\"\n spec:\n serviceAccountName: heapster\n containers:\n - image: ${heapster_image}\n name: heapster\n livenessProbe:\n httpGet:\n path: /healthz\n port: 8082\n scheme: HTTP\n initialDelaySeconds: 180\n timeoutSeconds: 5\n resources:\n # keep request = limit to keep this container in guaranteed class\n limits:\n cpu: 100m\n memory: 300Mi\n requests:\n cpu: 100m\n memory: 300Mi\n command:\n - /heapster\n - --source=kubernetes:https://kubernetes.default\n - --sink=influxdb:http://${influxdb_service_name}.kube-system.svc:8086\n nodeSelector:\n ${node_selecter_label}\n---\napiVersion: v1\nkind: Service\nmetadata:\n name: heapster\n namespace: kube-system\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\n kubernetes.io/name: \"Heapster\"\n kubernetes.io/cluster-service: \"true\"\nspec:\n ports:\n - port: 80\n targetPort: 8082\n selector:\n k8s-app: heapster\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n name: heapster\n namespace: kube-system\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n name: heapster\n labels:\n k8s-addon: monitoring-standalone.addons.k8s.io\nroleRef:\n apiGroup: rbac.authorization.k8s.io\n kind: ClusterRole\n name: system:heapster\nsubjects:\n- kind: ServiceAccount\n name: heapster\n namespace: kube-system", "vars.%": "3", "vars.heapster_image": "gcr.io/google_containers/heapster-amd64:v1.5.0", "vars.influxdb_service_name": "monitoring-influxdb", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "k8s-addons", "monitoring-addons", "influxdb-addon" ], "outputs": {}, "resources": { "data.template_file.influxdb_cluster_addon_config": { "type": "template_file", "depends_on": [], "primary": { "id": "8cd7742e7fd088394ec6a81ffb0a48a9dbe53d70de3d899fa98e09bdda1baf8e", "attributes": { "id": "8cd7742e7fd088394ec6a81ffb0a48a9dbe53d70de3d899fa98e09bdda1baf8e", "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: influxdb-configmap\n namespace: kube-system\ndata:\n influxdb.toml: |-\n reporting-disabled = true\n bind-address = \"localhost:8088\"\n\n [admin]\n enabled = true\n [meta]\n dir = \"/data/meta\"\n retention-autocreate = true\n logging-enabled = true\n\n [data]\n dir = \"/data/data\"\n wal-dir = \"/data/wal\"\n query-log-enabled = true\n cache-max-memory-size = 1073741824\n cache-snapshot-memory-size = 26214400\n cache-snapshot-write-cold-duration = \"10m0s\"\n compact-full-write-cold-duration = \"4h0m0s\"\n max-series-per-database = 1000000\n max-values-per-tag = 100000\n trace-logging-enabled = false\n\n [coordinator]\n write-timeout = \"10s\"\n max-concurrent-queries = 0\n query-timeout = \"0s\"\n log-queries-after = \"0s\"\n max-select-point = 0\n max-select-series = 0\n max-select-buckets = 0\n\n [retention]\n enabled = true\n check-interval = \"30m0s\"\n\n [shard-precreation]\n enabled = true\n check-interval = \"10m0s\"\n advance-period = \"30m0s\"\n\n [monitor]\n store-enabled = true\n store-database = \"_internal\"\n store-interval = \"10s\"\n\n [subscriber]\n enabled = true\n http-timeout = \"30s\"\n insecure-skip-verify = false\n ca-certs = \"\"\n write-concurrency = 40\n write-buffer-size = 1000\n\n [http]\n enabled = true\n bind-address = \":8086\"\n auth-enabled = false\n log-enabled = true\n write-tracing = false\n pprof-enabled = false\n https-enabled = false\n https-certificate = \"/etc/ssl/influxdb.pem\"\n https-private-key = \"\"\n max-row-limit = 10000\n max-connection-limit = 0\n shared-secret = \"\"\n realm = \"InfluxDB\"\n unix-socket-enabled = false\n bind-socket = \"/var/run/influxdb.sock\"\n\n [[graphite]]\n enabled = true\n bind-address = \":2003\"\n database = \"graphite\"\n retention-policy = \"\"\n protocol = \"tcp\"\n batch-size = 5000\n batch-pending = 10\n batch-timeout = \"1s\"\n consistency-level = \"one\"\n separator = \".\"\n udp-read-buffer = 0\n templates = [\n \"haystack.buckets.* measurement.measurement.measurement.measurement.host.bucket.field*\",\n \"haystack.errors.* measurement.measurement.measurement.fqClass.host.field*\",\n \"haystack.* measurement.measurement.measurement.host.class.field*\",\n ]\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n task: monitoring\n kubernetes.io/cluster-service: \"true\"\n kubernetes.io/name: monitoring-influxdb\n name: monitoring-influxdb\n namespace: kube-system\nspec:\n ports:\n - port: 8086\n targetPort: 8086\n selector:\n k8s-app: monitoring-influxdb\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n task: monitoring\n kubernetes.io/cluster-service: \"true\"\n kubernetes.io/name: monitoring-influxdb\n name: monitoring-influxdb-graphite\n namespace: kube-system\nspec:\n type: NodePort\n ports:\n - port: 2003\n name: tcp\n targetPort: 2003\n nodePort: 32301\n selector:\n k8s-app: monitoring-influxdb\n---\napiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n name: monitoring-influxdb\n namespace: kube-system\n labels:\n k8s-addon: monitoring-complete.addons.k8s.io\n k8s-app: monitoring-influxdb\n version: v1\n kubernetes.io/cluster-service: \"true\"\nspec:\n serviceName: monitoring-influxdb\n replicas: 1\n template:\n metadata:\n labels:\n task: monitoring\n k8s-app: monitoring-influxdb\n spec:\n containers:\n - name: influxdb\n image: influxdb:1.6\n resources:\n # keep request = limit to keep this container in guaranteed class\n limits:\n memory: 1024Mi\n ports:\n - containerPort: 8083\n volumeMounts:\n - mountPath: /data\n name: influxdb-persistent-storage\n - name: config-volume\n mountPath: \"/etc/influxdb\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: \"influxdb-configmap\"\n items:\n - key: \"influxdb.toml\"\n path: \"config.toml\"\n volumeClaimTemplates:\n - metadata:\n name: influxdb-persistent-storage\n annotations:\n volume.beta.kubernetes.io/storage-class: \"default\"\n spec:\n storageClassName: \"default\"\n accessModes: [\"ReadWriteOnce\"]\n resources:\n requests:\n storage: 100Mi\n", "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: influxdb-configmap\n namespace: kube-system\ndata:\n influxdb.toml: |-\n reporting-disabled = true\n bind-address = \"localhost:8088\"\n\n [admin]\n enabled = true\n [meta]\n dir = \"/data/meta\"\n retention-autocreate = true\n logging-enabled = true\n\n [data]\n dir = \"/data/data\"\n wal-dir = \"/data/wal\"\n query-log-enabled = true\n cache-max-memory-size = 1073741824\n cache-snapshot-memory-size = 26214400\n cache-snapshot-write-cold-duration = \"10m0s\"\n compact-full-write-cold-duration = \"4h0m0s\"\n max-series-per-database = 1000000\n max-values-per-tag = 100000\n trace-logging-enabled = false\n\n [coordinator]\n write-timeout = \"10s\"\n max-concurrent-queries = 0\n query-timeout = \"0s\"\n log-queries-after = \"0s\"\n max-select-point = 0\n max-select-series = 0\n max-select-buckets = 0\n\n [retention]\n enabled = true\n check-interval = \"30m0s\"\n\n [shard-precreation]\n enabled = true\n check-interval = \"10m0s\"\n advance-period = \"30m0s\"\n\n [monitor]\n store-enabled = true\n store-database = \"_internal\"\n store-interval = \"10s\"\n\n [subscriber]\n enabled = true\n http-timeout = \"30s\"\n insecure-skip-verify = false\n ca-certs = \"\"\n write-concurrency = 40\n write-buffer-size = 1000\n\n [http]\n enabled = true\n bind-address = \":8086\"\n auth-enabled = false\n log-enabled = true\n write-tracing = false\n pprof-enabled = false\n https-enabled = false\n https-certificate = \"/etc/ssl/influxdb.pem\"\n https-private-key = \"\"\n max-row-limit = 10000\n max-connection-limit = 0\n shared-secret = \"\"\n realm = \"InfluxDB\"\n unix-socket-enabled = false\n bind-socket = \"/var/run/influxdb.sock\"\n\n [[graphite]]\n enabled = true\n bind-address = \":2003\"\n database = \"graphite\"\n retention-policy = \"\"\n protocol = \"tcp\"\n batch-size = 5000\n batch-pending = 10\n batch-timeout = \"1s\"\n consistency-level = \"one\"\n separator = \".\"\n udp-read-buffer = 0\n templates = [\n \"haystack.buckets.* measurement.measurement.measurement.measurement.host.bucket.field*\",\n \"haystack.errors.* measurement.measurement.measurement.fqClass.host.field*\",\n \"haystack.* measurement.measurement.measurement.host.class.field*\",\n ]\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n task: monitoring\n kubernetes.io/cluster-service: \"true\"\n kubernetes.io/name: monitoring-influxdb\n name: monitoring-influxdb\n namespace: kube-system\nspec:\n ports:\n - port: 8086\n targetPort: 8086\n selector:\n k8s-app: monitoring-influxdb\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n task: monitoring\n kubernetes.io/cluster-service: \"true\"\n kubernetes.io/name: monitoring-influxdb\n name: monitoring-influxdb-graphite\n namespace: kube-system\nspec:\n type: NodePort\n ports:\n - port: 2003\n name: tcp\n targetPort: 2003\n nodePort: ${graphite_node_port}\n selector:\n k8s-app: monitoring-influxdb\n---\napiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n name: monitoring-influxdb\n namespace: kube-system\n labels:\n k8s-addon: monitoring-complete.addons.k8s.io\n k8s-app: monitoring-influxdb\n version: v1\n kubernetes.io/cluster-service: \"true\"\nspec:\n serviceName: monitoring-influxdb\n replicas: 1\n template:\n metadata:\n labels:\n task: monitoring\n k8s-app: monitoring-influxdb\n spec:\n containers:\n - name: influxdb\n image: ${influxdb_image}\n resources:\n # keep request = limit to keep this container in guaranteed class\n limits:\n memory: ${heap_memory_in_mb}Mi\n ports:\n - containerPort: 8083\n volumeMounts:\n - mountPath: /data\n name: influxdb-persistent-storage\n - name: config-volume\n mountPath: \"/etc/influxdb\"\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: \"influxdb-configmap\"\n items:\n - key: \"influxdb.toml\"\n path: \"config.toml\"\n volumeClaimTemplates:\n - metadata:\n name: influxdb-persistent-storage\n annotations:\n volume.beta.kubernetes.io/storage-class: \"${influxdb_storage_class}\"\n spec:\n storageClassName: \"${influxdb_storage_class}\"\n accessModes: [\"ReadWriteOnce\"]\n resources:\n requests:\n storage: ${influxdb_storage}\n", "vars.%": "6", "vars.graphite_node_port": "32301", "vars.heap_memory_in_mb": "1024", "vars.influxdb_image": "influxdb:1.6", "vars.influxdb_storage": "100Mi", "vars.influxdb_storage_class": "default", "vars.node_selecter_label": "kubernetes.io/hostname: minikube" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] } ] },"appsState":{ "version": 3, "terraform_version": "0.11.1", "serial": 11, "lineage": "4d59c6c0-b092-4031-95ad-2d28c45c2813", "modules": [ { "path": [ "root" ], "outputs": {}, "resources": { "data.terraform_remote_state.haystack_infrastructure": { "type": "terraform_remote_state", "depends_on": [], "primary": { "id": "2019-04-09 09:57:32.576578 +0000 UTC", "attributes": { "aa_app_namespace": "aa-apps", "backend": "local", "cassandra_hostname": "cassandra", "cassandra_port": "9042", "config.%": "1", "config.path": "../state/terraform-infra.tfstate", "elasticsearch_hostname": "elasticsearch", "elasticsearch_port": "9200", "environment": "default", "graphite_enabled": "false", "graphite_hostname": "monitoring-influxdb-graphite.kube-system.svc", "graphite_port": "2003", "id": "2019-04-09 09:57:32.576578 +0000 UTC", "k8s_app_namespace": "haystack-apps", "k8s_cluster_name": "minikube", "kafka_hostname": "kafka-service.haystack-apps.svc.cluster.local", "kafka_port": "9092" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.terraform" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "service-graph" ], "outputs": { "graph_builder_hostname": { "sensitive": false, "type": "string", "value": "graph-builder" }, "graph_builder_port": { "sensitive": false, "type": "string", "value": "8080" } }, "resources": {}, "depends_on": [] }, { "path": [ "root", "haystack-apps", "traces" ], "outputs": { "reader_hostname": { "sensitive": false, "type": "string", "value": "trace-reader" }, "reader_port": { "sensitive": false, "type": "string", "value": "8080" } }, "resources": {}, "depends_on": [] }, { "path": [ "root", "haystack-apps", "trends" ], "outputs": { "metrictank_hostname": { "sensitive": false, "type": "string", "value": "metrictank" }, "metrictank_port": { "sensitive": false, "type": "string", "value": "6060" } }, "resources": {}, "depends_on": [] }, { "path": [ "root", "haystack-apps", "ui" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "9336f2300068350533ded8c45cc81c75d091990c421eb98f540952aba259f1c3", "attributes": { "id": "9336f2300068350533ded8c45cc81c75d091990c421eb98f540952aba259f1c3", "rendered": "{\n \"port\": 8080,\n \"cluster\": true,\n \"upstreamTimeout\": 30000,\n \"enableServicePerformance\": false,\n \"enableServiceLevelTrends\": false,\n \"enableLatencyCostViewer\": true,\n \"graphite\": {\n \"host\": \"monitoring-influxdb-graphite.kube-system.svc\",\n \"port\": 2003\n },\n \"grpcOptions\": {\n \"grpc.max_receive_message_length\": 52428800\n }\n \"connectors\": {\n \"traces\": {\n \"connectorName\": \"haystack\",\n \"haystackHost\": \"trace-reader\",\n \"haystackPort\": 8080,\n \"serviceRefreshIntervalInSecs\": 60,\n \"fieldKeys\": [],\n },\n \"trends\": {\n \"connectorName\": \"haystack\",\n \"metricTankUrl\": \"http://metrictank:6060\",\n \"encoder\": \"base64\"\n\n },\n \"alerts\": {\n \"connectorName\": \"haystack\",\n \"metricTankUrl\": \"http://metrictank:6060\",\n \"alertFreqInSec\": 300,\n \"alertMergeBufferTimeInSec\": 60,\n \"subscriptions\": {\n \"connectorName\": \"stub\",\n \"enabled\": false\n }\n }\n },\n \"enableSSO\": 0,\n \"saml\": {\n \"callbackUrl\": \"\",\n \"entry_point\": \"\",\n \"issuer\": \"\"\n },\n \"sessionTimeout\": 3600000,\n \"sessionSecret\": \"\"\n}\n", "template": "{\n \"port\": 8080,\n \"cluster\": true,\n \"upstreamTimeout\": 30000,\n \"enableServicePerformance\": false,\n \"enableServiceLevelTrends\": false,\n \"enableLatencyCostViewer\": true,\n \"graphite\": {\n \"host\": \"${graphite_hostname}\",\n \"port\": ${graphite_port}\n },\n \"grpcOptions\": {\n \"grpc.max_receive_message_length\": 52428800\n }\n \"connectors\": {\n \"traces\": {\n \"connectorName\": \"haystack\",\n \"haystackHost\": \"${trace_reader_hostname}\",\n \"haystackPort\": ${trace_reader_service_port},\n \"serviceRefreshIntervalInSecs\": 60,\n \"fieldKeys\": [${whitelisted_fields}],\n },\n \"trends\": {\n \"connectorName\": \"haystack\",\n \"metricTankUrl\": \"http://${metrictank_hostname}:${metrictank_port}\",\n \"encoder\": \"${metricpoint_encoder_type}\"\n\n },\n \"alerts\": {\n \"connectorName\": \"haystack\",\n \"metricTankUrl\": \"http://${metrictank_hostname}:${metrictank_port}\",\n \"alertFreqInSec\": 300,\n \"alertMergeBufferTimeInSec\": 60,\n \"subscriptions\": {\n \"connectorName\": \"stub\",\n \"enabled\": false\n }\n }\n },\n \"enableSSO\": ${ui_enable_sso},\n \"saml\": {\n \"callbackUrl\": \"${ui_saml_callback_url}\",\n \"entry_point\": \"${ui_saml_entry_point}\",\n \"issuer\": \"${ui_saml_issuer}\"\n },\n \"sessionTimeout\": 3600000,\n \"sessionSecret\": \"${ui_session_secret}\"\n}\n", "vars.%": "13", "vars.graphite_hostname": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.metricpoint_encoder_type": "base64", "vars.metrictank_hostname": "metrictank", "vars.metrictank_port": "6060", "vars.trace_reader_hostname": "trace-reader", "vars.trace_reader_service_port": "8080", "vars.ui_enable_sso": "0", "vars.ui_saml_callback_url": "", "vars.ui_saml_entry_point": "", "vars.ui_saml_issuer": "", "vars.ui_session_secret": "", "vars.whitelisted_fields": "" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "00ad8e4608884a9bb6fde497e0c705f0760b624a57be3bb7a2478e8426828017", "attributes": { "id": "00ad8e4608884a9bb6fde497e0c705f0760b624a57be3bb7a2478e8426828017", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: haystack-ui\n name: haystack-ui\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: haystack-ui\n template:\n metadata:\n labels:\n k8s-app: haystack-ui\n spec:\n containers:\n - name: haystack-ui\n image: expediadotcom/haystack-ui:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/haystack-ui.json\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: haystack-ui\n name: haystack-ui\n namespace: haystack-apps\nspec:\n ports:\n - port: 80\n targetPort: 8080\n selector:\n k8s-app: haystack-ui\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_limit}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/haystack-ui.json\"\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}\n", "vars.%": "12", "vars.app_name": "haystack-ui", "vars.configmap_name": "ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b", "vars.container_port": "8080", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.image": "expediadotcom/haystack-ui:1.1", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "80" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "kubernetes_config_map.haystack-config": { "type": "kubernetes_config_map", "depends_on": [ "data.template_file.config_data", "local.configmap_name", "local.count" ], "primary": { "id": "haystack-apps/ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b", "attributes": { "data.%": "1", "data.haystack-ui.json": "{\n \"port\": 8080,\n \"cluster\": true,\n \"upstreamTimeout\": 30000,\n \"enableServicePerformance\": false,\n \"enableServiceLevelTrends\": false,\n \"enableLatencyCostViewer\": true,\n \"graphite\": {\n \"host\": \"monitoring-influxdb-graphite.kube-system.svc\",\n \"port\": 2003\n },\n \"grpcOptions\": {\n \"grpc.max_receive_message_length\": 52428800\n }\n \"connectors\": {\n \"traces\": {\n \"connectorName\": \"haystack\",\n \"haystackHost\": \"trace-reader\",\n \"haystackPort\": 8080,\n \"serviceRefreshIntervalInSecs\": 60,\n \"fieldKeys\": [],\n },\n \"trends\": {\n \"connectorName\": \"haystack\",\n \"metricTankUrl\": \"http://metrictank:6060\",\n \"encoder\": \"base64\"\n\n },\n \"alerts\": {\n \"connectorName\": \"haystack\",\n \"metricTankUrl\": \"http://metrictank:6060\",\n \"alertFreqInSec\": 300,\n \"alertMergeBufferTimeInSec\": 60,\n \"subscriptions\": {\n \"connectorName\": \"stub\",\n \"enabled\": false\n }\n }\n },\n \"enableSSO\": 0,\n \"saml\": {\n \"callbackUrl\": \"\",\n \"entry_point\": \"\",\n \"issuer\": \"\"\n },\n \"sessionTimeout\": 3600000,\n \"sessionSecret\": \"\"\n}\n", "id": "haystack-apps/ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b", "metadata.#": "1", "metadata.0.annotations.%": "0", "metadata.0.generate_name": "", "metadata.0.generation": "0", "metadata.0.labels.%": "0", "metadata.0.name": "ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b", "metadata.0.namespace": "haystack-apps", "metadata.0.resource_version": "513", "metadata.0.self_link": "/api/v1/namespaces/haystack-apps/configmaps/ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b", "metadata.0.uid": "dabf58e4-5a8e-11e9-82ec-080027a2c57a" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.kubernetes" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml", "local.count" ], "primary": { "id": "2372195201708263408", "attributes": { "id": "2372195201708263408", "triggers.%": "1", "triggers.template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: haystack-ui\n name: haystack-ui\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: haystack-ui\n template:\n metadata:\n labels:\n k8s-app: haystack-ui\n spec:\n containers:\n - name: haystack-ui\n image: expediadotcom/haystack-ui:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/haystack-ui.json\"\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: ui-fb68cf490de8bb9c228b0167dfe5b4d8e1edfc4b\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: haystack-ui\n name: haystack-ui\n namespace: haystack-apps\nspec:\n ports:\n - port: 80\n targetPort: 8080\n selector:\n k8s-app: haystack-ui\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.kubectl_destroy": { "type": "null_resource", "depends_on": [ "local.count" ], "primary": { "id": "2447721327108067511", "attributes": { "id": "2447721327108067511" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "collectors", "http-span-collector" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "838cc76cb7bc48bbf53571927fe4e2972d78b2af97bc5cc618d6e72412e14d5a", "attributes": { "id": "838cc76cb7bc48bbf53571927fe4e2972d78b2af97bc5cc618d6e72412e14d5a", "rendered": "kafka {\n producer {\n topic = \"proto-spans\"\n props {\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n retries = 50\n batch.size = 153600\n linger.ms = 250\n compression.type = \"lz4\"\n }\n }\n}\n\nextractor {\n output.format = \"proto\"\n}\n\nhttp {\n host = \"0.0.0.0\"\n port = 8080\n}\n\n", "template": "kafka {\n producer {\n topic = \"proto-spans\"\n props {\n bootstrap.servers = \"${kafka_endpoint}\"\n retries = 50\n batch.size = 153600\n linger.ms = 250\n compression.type = \"lz4\"\n }\n }\n}\n\nextractor {\n output.format = \"proto\"\n}\n\nhttp {\n host = \"0.0.0.0\"\n port = ${container_port}\n}\n\n", "vars.%": "2", "vars.container_port": "8080", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "1ac37cac52c32a44e858420acd4f59930212c12d577c067fd1c461fcc6785971", "attributes": { "id": "1ac37cac52c32a44e858420acd4f59930212c12d577c067fd1c461fcc6785971", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: http-span-collector}\n name: http-span-collector}\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: http-span-collector}\n template:\n metadata:\n labels:\n k8s-app: http-span-collector}\n spec:\n containers:\n - name: http-span-collector}\n image: expediadotcom/haystack-http-span-collector:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/http-span-collector.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n httpGet:\n path: /isActive\n port: 8080\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: http-span-collector}-d3a76ebf0c7da4807612488a9d71535beab1fe37\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: http-span-collector}\n name: http-span-collector}\n namespace: haystack-apps\nspec:\n ports:\n - port: 80\n targetPort: 8080\n selector:\n k8s-app: http-span-collector}\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/http-span-collector.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n httpGet:\n path: /isActive\n port: ${container_port}\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}\n", "vars.%": "16", "vars.app_name": "http-span-collector}", "vars.configmap_name": "http-span-collector}-d3a76ebf0c7da4807612488a9d71535beab1fe37", "vars.container_port": "8080", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-http-span-collector:1.1", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "80" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "collectors", "kinesis-span-collector" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "30a2e97e68e2fe6c914bc49efb60430baa313003701d1dded08ae95d177a581c", "attributes": { "id": "30a2e97e68e2fe6c914bc49efb60430baa313003701d1dded08ae95d177a581c", "rendered": "kafka {\n producer {\n topic = \"proto-spans\"\n props {\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n retries = 50\n batch.size = 153600\n linger.ms = 250\n compression.type = \"lz4\"\n }\n }\n}\n\nkinesis {\n sts.role.arn = \"\"\n aws.region = \"\"\n app.group.name = \"haystack-kinesis-span-collector\"\n\n stream {\n name = \"\"\n position = \"LATEST\"\n }\n\n checkpoint {\n interval.ms = 15000\n retries = 50\n retry.interval.ms = 250\n }\n\n task.backoff.ms = 200\n max.records.read = 2000\n idle.time.between.reads.ms = 500\n shard.sync.interval.ms = 30000\n\n metrics {\n level = \"NONE\"\n buffer.time.ms = 15000\n }\n}\n", "template": "kafka {\n producer {\n topic = \"proto-spans\"\n props {\n bootstrap.servers = \"${kafka_endpoint}\"\n retries = 50\n batch.size = 153600\n linger.ms = 250\n compression.type = \"lz4\"\n }\n }\n}\n\nkinesis {\n sts.role.arn = \"${sts_role_arn}\"\n aws.region = \"${kinesis_stream_region}\"\n app.group.name = \"${app_group_name}\"\n\n stream {\n name = \"${kinesis_stream_name}\"\n position = \"LATEST\"\n }\n\n checkpoint {\n interval.ms = 15000\n retries = 50\n retry.interval.ms = 250\n }\n\n task.backoff.ms = 200\n max.records.read = 2000\n idle.time.between.reads.ms = 500\n shard.sync.interval.ms = 30000\n\n metrics {\n level = \"NONE\"\n buffer.time.ms = 15000\n }\n}\n", "vars.%": "5", "vars.app_group_name": "haystack-kinesis-span-collector", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092", "vars.kinesis_stream_name": "", "vars.kinesis_stream_region": "", "vars.sts_role_arn": "" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "e41f7828a08bde63b66b053ddb063d86a055102cbebaca96f3d3e16003fd5ecb", "attributes": { "id": "e41f7828a08bde63b66b053ddb063d86a055102cbebaca96f3d3e16003fd5ecb", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: kinesis-span-collector\n name: kinesis-span-collector\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: kinesis-span-collector\n template:\n metadata:\n labels:\n k8s-app: kinesis-span-collector\n spec:\n containers:\n - name: kinesis-span-collector\n image: expediadotcom/haystack-kinesis-span-collector:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/kinesis-span-collector.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: kinesis-span-collector-f84aef6a4159e0deea5e3c8e9cf515647814df88\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/kinesis-span-collector.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n", "vars.%": "14", "vars.app_name": "kinesis-span-collector", "vars.configmap_name": "kinesis-span-collector-f84aef6a4159e0deea5e3c8e9cf515647814df88", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-kinesis-span-collector:1.1", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "pipes", "pipes-firehose-writer" ], "outputs": {}, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.deployment_yaml_file_path" ], "primary": { "id": "43c021afd9ca778d7a8904facccad3d3d8a99953d6ffc727d9c8678a62e81174", "attributes": { "id": "43c021afd9ca778d7a8904facccad3d3d8a99953d6ffc727d9c8678a62e81174", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: pipes-firehose-writer\n name: pipes-firehose-writer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: pipes-firehose-writer\n template:\n metadata:\n labels:\n k8s-app: pipes-firehose-writer\n spec:\n containers:\n - name: pipes-firehose-writer\n image: expediadotcom/haystack-pipes-firehose-writer:a20a8087f5ddc3fbf1a1c72dcff840608accadbf\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_FIREHOSE_INITIALRETRYSLEEP\"\n value: \"1\"\n - name: \"HAYSTACK_FIREHOSE_MAXRETRYSLEEP\"\n value: \"\"\n - name: \"HAYSTACK_FIREHOSE_SIGNINGREGION\"\n value: \"\"\n - name: \"HAYSTACK_FIREHOSE_STREAMNAME\"\n value: \"\"\n - name: \"HAYSTACK_FIREHOSE_URL\"\n value: \"\"\n - name: \"HAYSTACK_KAFKA_FROMTOPIC\"\n value: \"\"\n - name: \"HAYSTACK_KAFKA_THREADCOUNT\"\n value: \"1\"\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_FIREHOSE_USESTRINGBUFFERING\"\n value: \"true\"\n - name: \"HAYSTACK_FIREHOSE_MAXBATCHINTERVAL\"\n value: \"0\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_FIREHOSE_INITIALRETRYSLEEP\"\n value: \"${firehose_initialretrysleep}\"\n - name: \"HAYSTACK_FIREHOSE_MAXRETRYSLEEP\"\n value: \"${firehose_maxretrysleep}\"\n - name: \"HAYSTACK_FIREHOSE_SIGNINGREGION\"\n value: \"${firehose_region}\"\n - name: \"HAYSTACK_FIREHOSE_STREAMNAME\"\n value: \"${firehose_stream_name}\"\n - name: \"HAYSTACK_FIREHOSE_URL\"\n value: \"${firehose_url}\"\n - name: \"HAYSTACK_KAFKA_FROMTOPIC\"\n value: \"${firehose_writer_haystack_kafka_fromtopic}\"\n - name: \"HAYSTACK_KAFKA_THREADCOUNT\"\n value: \"${firehose_kafka_threadcount}\"\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"${kafka_hostname}\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_FIREHOSE_USESTRINGBUFFERING\"\n value: \"${firehose_usestringbuffering}\"\n - name: \"HAYSTACK_FIREHOSE_MAXBATCHINTERVAL\"\n value: \"${firehose_maxbatchinterval}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n\n", "vars.%": "23", "vars.app_name": "pipes-firehose-writer", "vars.cpu_limit": "500m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.firehose_initialretrysleep": "1", "vars.firehose_kafka_threadcount": "1", "vars.firehose_maxbatchinterval": "0", "vars.firehose_maxretrysleep": "", "vars.firehose_region": "", "vars.firehose_stream_name": "", "vars.firehose_url": "", "vars.firehose_usestringbuffering": "true", "vars.firehose_writer_haystack_kafka_fromtopic": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-pipes-firehose-writer:a20a8087f5ddc3fbf1a1c72dcff840608accadbf", "vars.jvm_memory_limit": "200", "vars.kafka_hostname": "kafka-service.haystack-apps.svc.cluster.local", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "pipes", "pipes-http-poster" ], "outputs": {}, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.deployment_yaml_file_path" ], "primary": { "id": "d51cd12e3cd8456c4de89d2785b43360198ba6afd3e03c2d2b2ac2fc38090551", "attributes": { "id": "d51cd12e3cd8456c4de89d2785b43360198ba6afd3e03c2d2b2ac2fc38090551", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: pipes-http-poster\n name: pipes-http-poster\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: pipes-http-poster\n template:\n metadata:\n labels:\n k8s-app: pipes-http-poster\n spec:\n containers:\n - name: pipes-http-poster\n image: expediadotcom/haystack-pipes-http-poster:a20a8087f5ddc3fbf1a1c72dcff840608accadbf\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_HTTPPOST_POLLPERCENT\"\n value: \"\"\n - name: \"HAYSTACK_HTTPPOST_URL\"\n value: \"\"\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n nodeSelector:\n kubernetes.io/hostname: minikube\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_HTTPPOST_POLLPERCENT\"\n value: \"${http_poster_httppost_pollpercent}\"\n - name: \"HAYSTACK_HTTPPOST_URL\"\n value: \"${httppost_url}\"\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"${kafka_hostname}\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n nodeSelector:\n ${node_selecter_label}\n\n", "vars.%": "16", "vars.app_name": "pipes-http-poster", "vars.cpu_limit": "500m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.http_poster_httppost_pollpercent": "", "vars.httppost_url": "", "vars.image": "expediadotcom/haystack-pipes-http-poster:a20a8087f5ddc3fbf1a1c72dcff840608accadbf", "vars.jvm_memory_limit": "200", "vars.kafka_hostname": "kafka-service.haystack-apps.svc.cluster.local", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "pipes", "pipes-json-transformer" ], "outputs": {}, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.deployment_yaml_file_path" ], "primary": { "id": "8084f17bf5ff23e4ae00ddd9c23723849ef44bc143c060b654b996104c6894f3", "attributes": { "id": "8084f17bf5ff23e4ae00ddd9c23723849ef44bc143c060b654b996104c6894f3", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: pipes-json-transformer\n name: pipes-json-transformer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: pipes-json-transformer\n template:\n metadata:\n labels:\n k8s-app: pipes-json-transformer\n spec:\n containers:\n - name: pipes-json-transformer\n image: expediadotcom/haystack-pipes-json-transformer:a20a8087f5ddc3fbf1a1c72dcff840608accadbf\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n nodeSelector:\n kubernetes.io/hostname: minikube\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"${kafka_hostname}\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n nodeSelector:\n ${node_selecter_label}\n\n", "vars.%": "14", "vars.app_name": "pipes-json-transformer", "vars.cpu_limit": "500m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-pipes-json-transformer:a20a8087f5ddc3fbf1a1c72dcff840608accadbf", "vars.jvm_memory_limit": "200", "vars.kafka_hostname": "kafka-service.haystack-apps.svc.cluster.local", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "pipes", "pipes-kafka-producer" ], "outputs": {}, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.deployment_yaml_file_path" ], "primary": { "id": "1a042d9516167e99783eb986ae763885443894f818d8aee5cd38fa6de98f595f", "attributes": { "id": "1a042d9516167e99783eb986ae763885443894f818d8aee5cd38fa6de98f595f", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: pipes-kafka-producer\n name: pipes-kafka-producer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: pipes-kafka-producer\n template:\n metadata:\n labels:\n k8s-app: pipes-kafka-producer\n spec:\n containers:\n - name: pipes-kafka-producer\n image: expediadotcom/haystack-pipes-kafka-producer:a20a8087f5ddc3fbf1a1c72dcff840608accadbf\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n nodeSelector:\n kubernetes.io/hostname: minikube\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"${kafka_hostname}\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n nodeSelector:\n ${node_selecter_label}\n\n", "vars.%": "14", "vars.app_name": "pipes-kafka-producer", "vars.cpu_limit": "500m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-pipes-kafka-producer:a20a8087f5ddc3fbf1a1c72dcff840608accadbf", "vars.jvm_memory_limit": "200", "vars.kafka_hostname": "kafka-service.haystack-apps.svc.cluster.local", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "pipes", "pipes-secret-detector" ], "outputs": {}, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.deployment_yaml_file_path" ], "primary": { "id": "a901a3a76517569e8ef0b6402b6371d9e8cc9837dd6608c0946df85ffd74e49f", "attributes": { "id": "a901a3a76517569e8ef0b6402b6371d9e8cc9837dd6608c0946df85ffd74e49f", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: pipes-secret-detector\n name: pipes-secret-detector\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: pipes-secret-detector\n template:\n metadata:\n labels:\n k8s-app: pipes-secret-detector\n spec:\n containers:\n - name: pipes-secret-detector\n image: expediadotcom/haystack-pipes-secret-detector:a20a8087f5ddc3fbf1a1c72dcff840608accadbf\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local\"\n - name: \"HAYSTACK_KAFKA_THREADCOUNT\"\n value: \"1\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_FROM\"\n value: \"\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_HOST\"\n value: \"\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_SUBJECT\"\n value: \"\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_TOS\"\n value: \"\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_WHITELIST_BUCKET\"\n value: \"\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_KAFKA_BROKERS\"\n value: \"${kafka_hostname}\"\n - name: \"HAYSTACK_KAFKA_THREADCOUNT\"\n value: \"${pipes_secret_detector_kafka_threadcount}\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_FROM\"\n value: \"${pipes_secret_detector_secretsnotifications_email_from}\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_HOST\"\n value: \"${pipes_secret_detector_secretsnotifications_email_host}\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_SUBJECT\"\n value: \"${pipes_secret_detector_secretsnotifications_email_subject}\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_EMAIL_TOS\"\n value: \"${pipes_secret_detector_secretsnotifications_email_tos}\"\n - name: \"HAYSTACK_SECRETSNOTIFICATIONS_WHITELIST_BUCKET\"\n value: \"${pipes_secret_detector_secretsnotifications_whitelist_bucket}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n\n", "vars.%": "20", "vars.app_name": "pipes-secret-detector", "vars.cpu_limit": "500m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-pipes-secret-detector:a20a8087f5ddc3fbf1a1c72dcff840608accadbf", "vars.jvm_memory_limit": "200", "vars.kafka_hostname": "kafka-service.haystack-apps.svc.cluster.local", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.pipes_secret_detector_kafka_threadcount": "1", "vars.pipes_secret_detector_secretsnotifications_email_from": "", "vars.pipes_secret_detector_secretsnotifications_email_host": "", "vars.pipes_secret_detector_secretsnotifications_email_subject": "", "vars.pipes_secret_detector_secretsnotifications_email_tos": "", "vars.pipes_secret_detector_secretsnotifications_whitelist_bucket": "", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "service-graph", "graph-builder" ], "outputs": { "hostname": { "sensitive": false, "type": "string", "value": "graph-builder" }, "service_port": { "sensitive": false, "type": "string", "value": "8080" } }, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "d729dd9bbd9dbca865bd7530781e51af971631c37c567bef729fa5256e31f01c", "attributes": { "id": "d729dd9bbd9dbca865bd7530781e51af971631c37c567bef729fa5256e31f01c", "rendered": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"haystack-service-graph-graph-builder\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 4\n request.timeout.ms = 60000\n commit.interval.ms = 3000\n auto.offset.reset = latest\n timestamp.extractor = \"org.apache.kafka.streams.processor.WallclockTimestampExtractor\"\n replication.factor = 1\n }\n\n consumer {\n topic = \"graph-nodes\"\n }\n\n producer {\n topic = \"service-graph\"\n }\n\n aggregate {\n window.sec = 1800\n retention.days = 1\n }\n}\n\nservice {\n threads {\n min = 1\n max = 5\n idle.timeout = 12000\n }\n\n http {\n port = 8080\n idle.timeout = 12000\n }\n\n client {\n connection.timeout = 10000\n socket.timeout = 10000\n }\n}\n", "template": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"haystack-service-graph-graph-builder\"\n bootstrap.servers = \"${kafka_endpoint}\"\n num.stream.threads = 4\n request.timeout.ms = 60000\n commit.interval.ms = 3000\n auto.offset.reset = latest\n timestamp.extractor = \"org.apache.kafka.streams.processor.WallclockTimestampExtractor\"\n replication.factor = 1\n }\n\n consumer {\n topic = \"graph-nodes\"\n }\n\n producer {\n topic = \"service-graph\"\n }\n\n aggregate {\n window.sec = 1800\n retention.days = 1\n }\n}\n\nservice {\n threads {\n min = 1\n max = 5\n idle.timeout = 12000\n }\n\n http {\n port = 8080\n idle.timeout = 12000\n }\n\n client {\n connection.timeout = 10000\n socket.timeout = 10000\n }\n}\n", "vars.%": "1", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "70a3336e7606df01924e0e5b55929286b6cfde39607fb29341b4e08b9a9d2b09", "attributes": { "id": "70a3336e7606df01924e0e5b55929286b6cfde39607fb29341b4e08b9a9d2b09", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: graph-builder\n name: graph-builder\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: graph-builder\n template:\n metadata:\n labels:\n k8s-app: graph-builder\n spec:\n containers:\n - name: graph-builder\n image: expediadotcom/haystack-service-graph-graph-builder:1.0\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/graph-builder.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_PROP_SERVICE_HOST\"\n valueFrom:\n fieldRef:\n fieldPath: status.podIP\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 2\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: graph-builder-834dffe27576a81efce185b3a0cc45caf1a079a6\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: graph-builder\n name: graph-builder\n namespace: haystack-apps\nspec:\n ports:\n - port: 8080\n targetPort: 8080\n selector:\n k8s-app: graph-builder\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/graph-builder.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_PROP_SERVICE_HOST\"\n valueFrom:\n fieldRef:\n fieldPath: status.podIP\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 2\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}\n", "vars.%": "16", "vars.app_name": "graph-builder", "vars.configmap_name": "graph-builder-834dffe27576a81efce185b3a0cc45caf1a079a6", "vars.container_port": "8080", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-service-graph-graph-builder:1.0", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "8080" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "service-graph", "node-finder" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "487927f6229ae932b763889ebfbc48fc68a603ce6a109d455e979ac035ba6451", "attributes": { "id": "487927f6229ae932b763889ebfbc48fc68a603ce6a109d455e979ac035ba6451", "rendered": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"haystack-service-graph-node-finder\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 4\n request.timeout.ms = 60000\n commit.interval.ms = 3000\n auto.offset.reset = latest\n }\n\n producer {\n metrics {\n topic = \"metricpoints\"\n // there are three types of encoders that are used on service and operation names:\n // 1) periodreplacement: replaces all periods with 3 underscores\n // 2) base64: base64 encodes the full name with a padding of _\n // 3) noop: does not perform any encoding\n key.encoder = \"base64\"\n\n }\n service.call {\n topic = \"graph-nodes\"\n }\n }\n\n consumer {\n topic = \"proto-spans\"\n }\n\n accumulator {\n interval = 2500\n }\n // collector tags allow service graph to collect tags from spans and have them available when querying service\n // graph. Example: you can collect the tags service tier and infraprovider tags using value \"[tier,infraprovider]\"\n collectorTags = []\n\n node.metadata {\n topic {\n autocreate = true\n name = \"haystack-node-finder-metadata\"\n partition.count = 6\n replication.factor = 2\n }\n }\n}\n\n", "template": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"haystack-service-graph-node-finder\"\n bootstrap.servers = \"${kafka_endpoint}\"\n num.stream.threads = 4\n request.timeout.ms = 60000\n commit.interval.ms = 3000\n auto.offset.reset = latest\n }\n\n producer {\n metrics {\n topic = \"metricpoints\"\n // there are three types of encoders that are used on service and operation names:\n // 1) periodreplacement: replaces all periods with 3 underscores\n // 2) base64: base64 encodes the full name with a padding of _\n // 3) noop: does not perform any encoding\n key.encoder = \"${metricpoint_encoder_type}\"\n\n }\n service.call {\n topic = \"graph-nodes\"\n }\n }\n\n consumer {\n topic = \"proto-spans\"\n }\n\n accumulator {\n interval = 2500\n }\n // collector tags allow service graph to collect tags from spans and have them available when querying service\n // graph. Example: you can collect the tags service tier and infraprovider tags using value \"[tier,infraprovider]\"\n collectorTags = ${collect_tags}\n\n node.metadata {\n topic {\n autocreate = true\n name = \"haystack-node-finder-metadata\"\n partition.count = 6\n replication.factor = 2\n }\n }\n}\n\n", "vars.%": "3", "vars.collect_tags": "[]", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092", "vars.metricpoint_encoder_type": "base64" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "839c1581d813811bed0e68ac61b02c029fdc0857719caa7d2058621502b05ece", "attributes": { "id": "839c1581d813811bed0e68ac61b02c029fdc0857719caa7d2058621502b05ece", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: node-finder\n name: node-finder\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: node-finder\n template:\n metadata:\n labels:\n k8s-app: node-finder\n spec:\n containers:\n - name: node-finder\n image: expediadotcom/haystack-service-graph-node-finder:1.0\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/node-finder.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"true\" \n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 2\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: node-finder-edfab65695597b27412b427a03c2b99d20749ad6\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/node-finder.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"true\" \n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 2\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n", "vars.%": "14", "vars.app_name": "node-finder", "vars.configmap_name": "node-finder-edfab65695597b27412b427a03c2b99d20749ad6", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-service-graph-node-finder:1.0", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "traces", "trace-indexer" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path", "local.elasticsearch_endpoint", "local.span_produce_topic" ], "primary": { "id": "e998b0ed5fdf7c94bdf03fb22f94516b52f29bf354cf5b22b279c35ebf07cbfd", "attributes": { "id": "e998b0ed5fdf7c94bdf03fb22f94516b52f29bf354cf5b22b279c35ebf07cbfd", "rendered": "health.status.path = \"/app/isHealthy\"\n\nspan.accumulate {\n store {\n min.traces.per.cache = 1000 # this defines the minimum traces in each cache before eviction check is applied. This is also useful for testing the code\n all.max.entries = 150000 # this is the maximum number of spans that can live across all the stores\n }\n window.ms = 10000\n poll.ms = 2000\n packer = zstd\n}\n\nkafka {\n close.stream.timeout.ms = 15000\n\n topic.consume = \"proto-spans\"\n topic.produce = \"\"\n\n num.stream.threads = 2\n poll.timeout.ms = 100\n\n # if consumer poll hangs, then wakeup it after after a timeout\n # also set the maximum wakeups allowed, if max threshold is reached, then task will raise the shutdown request\n max.wakeups = 10\n wakeup.timeout.ms = 3000\n\n commit.offset {\n retries = 3\n backoff.ms = 200\n }\n\n # consumer specific configurations\n consumer {\n group.id = \"haystack-proto-trace-indexer\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n auto.offset.reset = \"latest\"\n\n # disable auto commit as the app manages offset itself\n enable.auto.commit = \"false\"\n }\n\n # producer specific configurations\n producer {\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n }\n}\n\nbackend {\n\n client {\n host = \"localhost\"\n port = 8090\n }\n # defines the max inflight writes for backend client\n max.inflight.requests = 100\n}\nelasticsearch {\n endpoint = \"http://elasticsearch:9200\"\n\n # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk\n bulk.max {\n docs {\n count = 200\n size.kb = 1000\n }\n inflight = 25\n }\n\n conn.timeout.ms = 10000\n read.timeout.ms = 30000\n consistency.level = \"one\"\n max.connections.per.route = 5\n\n retries {\n max = 10\n backoff {\n initial.ms = 100\n factor = 2\n }\n }\n\n index {\n # apply the template before starting the client, if json is empty, no operation is performed\n template.json = \"\"\"{\"template\":\"haystack-traces*\",\"settings\":{\"number_of_shards\":4,\"index.mapping.ignore_malformed\":true,\"analysis\":{\"normalizer\":{\"lowercase_normalizer\":{\"type\":\"custom\",\"filter\":[\"lowercase\"]}}}},\"aliases\":{\"haystack-traces\":{}},\"mappings\":{\"spans\":{\"_field_names\":{\"enabled\":false},\"_all\":{\"enabled\":false},\"_source\":{\"includes\":[\"traceid\"]},\"properties\":{\"traceid\":{\"enabled\":false},\"starttime\":{\"type\":\"long\",\"doc_values\": true},\"spans\":{\"type\":\"nested\",\"properties\":{\"servicename\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false},\"operationname\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false},\"starttime\":{\"enabled\":false}}}},\"dynamic_templates\":[{\"strings_as_keywords_1\":{\"match_mapping_type\":\"string\",\"mapping\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false}}},{\"longs_disable_doc_norms\":{\"match_mapping_type\":\"long\",\"mapping\":{\"type\":\"long\",\"doc_values\":false,\"norms\":false}}}]}}}\"\"\"\n\n name.prefix = \"haystack-traces\"\n type = \"spans\"\n hour.bucket = 6\n }\n}\n\nservice.metadata {\n enabled = true\n flush {\n interval.sec = 60\n operation.count = 10000\n }\n es {\n endpoint = \"http://elasticsearch:9200\"\n conn.timeout.ms = 10000\n read.timeout.ms = 5000\n consistency.level = \"one\"\n index {\n # apply the template before starting the client, if json is empty, no operation is performed\n template.json = \"\"\"{\"template\": \"service-metadata*\", \"aliases\": {\"service-metadata\": {}}, \"settings\": {\"number_of_shards\": 4, \"index.mapping.ignore_malformed\": true, \"analysis\": {\"normalizer\": {\"lowercase_normalizer\": {\"type\": \"custom\", \"filter\": [\"lowercase\"]}}}}, \"mappings\": {\"metadata\": {\"_field_names\": {\"enabled\": false}, \"_all\": {\"enabled\": false}, \"properties\": {\"servicename\": {\"type\": \"keyword\", \"norms\": false}, \"operationname\": {\"type\": \"keyword\", \"doc_values\": false, \"norms\": false}}}}}\"\"\"\n name = \"service-metadata\"\n type = \"metadata\"\n }\n # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk\n bulk.max {\n docs {\n count = 100\n size.kb = 1000\n }\n inflight = 10\n }\n retries {\n max = 10\n backoff {\n initial.ms = 100\n factor = 2\n }\n }\n }\n}\n\nreload {\n tables {\n index.fields.config = \"indexing-fields\"\n }\n config {\n endpoint = \"http://elasticsearch:9200\"\n database.name = \"reload-configs\"\n }\n startup.load = true\n interval.ms = 60000 # -1 will imply 'no reload'\n}\n", "template": "health.status.path = \"/app/isHealthy\"\n\nspan.accumulate {\n store {\n min.traces.per.cache = 1000 # this defines the minimum traces in each cache before eviction check is applied. This is also useful for testing the code\n all.max.entries = 150000 # this is the maximum number of spans that can live across all the stores\n }\n window.ms = 10000\n poll.ms = 2000\n packer = zstd\n}\n\nkafka {\n close.stream.timeout.ms = 15000\n\n topic.consume = \"proto-spans\"\n topic.produce = \"${span_produce_topic}\"\n\n num.stream.threads = 2\n poll.timeout.ms = 100\n\n # if consumer poll hangs, then wakeup it after after a timeout\n # also set the maximum wakeups allowed, if max threshold is reached, then task will raise the shutdown request\n max.wakeups = 10\n wakeup.timeout.ms = 3000\n\n commit.offset {\n retries = 3\n backoff.ms = 200\n }\n\n # consumer specific configurations\n consumer {\n group.id = \"haystack-proto-trace-indexer\"\n bootstrap.servers = \"${kafka_endpoint}\"\n auto.offset.reset = \"latest\"\n\n # disable auto commit as the app manages offset itself\n enable.auto.commit = \"false\"\n }\n\n # producer specific configurations\n producer {\n bootstrap.servers = \"${kafka_endpoint}\"\n }\n}\n\nbackend {\n\n client {\n host = \"localhost\"\n port = 8090\n }\n # defines the max inflight writes for backend client\n max.inflight.requests = 100\n}\nelasticsearch {\n endpoint = \"http://${elasticsearch_endpoint}\"\n\n # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk\n bulk.max {\n docs {\n count = 200\n size.kb = 1000\n }\n inflight = 25\n }\n\n conn.timeout.ms = 10000\n read.timeout.ms = 30000\n consistency.level = \"one\"\n max.connections.per.route = 5\n\n retries {\n max = 10\n backoff {\n initial.ms = 100\n factor = 2\n }\n }\n\n index {\n # apply the template before starting the client, if json is empty, no operation is performed\n template.json = \"\"\"${elasticsearch_template}\"\"\"\n\n name.prefix = \"haystack-traces\"\n type = \"spans\"\n hour.bucket = 6\n }\n}\n\nservice.metadata {\n enabled = true\n flush {\n interval.sec = 60\n operation.count = 10000\n }\n es {\n endpoint = \"http://${elasticsearch_endpoint}\"\n conn.timeout.ms = 10000\n read.timeout.ms = 5000\n consistency.level = \"one\"\n index {\n # apply the template before starting the client, if json is empty, no operation is performed\n template.json = \"\"\"{\"template\": \"service-metadata*\", \"aliases\": {\"service-metadata\": {}}, \"settings\": {\"number_of_shards\": 4, \"index.mapping.ignore_malformed\": true, \"analysis\": {\"normalizer\": {\"lowercase_normalizer\": {\"type\": \"custom\", \"filter\": [\"lowercase\"]}}}}, \"mappings\": {\"metadata\": {\"_field_names\": {\"enabled\": false}, \"_all\": {\"enabled\": false}, \"properties\": {\"servicename\": {\"type\": \"keyword\", \"norms\": false}, \"operationname\": {\"type\": \"keyword\", \"doc_values\": false, \"norms\": false}}}}}\"\"\"\n name = \"service-metadata\"\n type = \"metadata\"\n }\n # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk\n bulk.max {\n docs {\n count = 100\n size.kb = 1000\n }\n inflight = 10\n }\n retries {\n max = 10\n backoff {\n initial.ms = 100\n factor = 2\n }\n }\n }\n}\n\nreload {\n tables {\n index.fields.config = \"indexing-fields\"\n }\n config {\n endpoint = \"http://${elasticsearch_endpoint}\"\n database.name = \"reload-configs\"\n }\n startup.load = true\n interval.ms = 60000 # -1 will imply 'no reload'\n}\n", "vars.%": "4", "vars.elasticsearch_endpoint": "elasticsearch:9200", "vars.elasticsearch_template": "{\"template\":\"haystack-traces*\",\"settings\":{\"number_of_shards\":4,\"index.mapping.ignore_malformed\":true,\"analysis\":{\"normalizer\":{\"lowercase_normalizer\":{\"type\":\"custom\",\"filter\":[\"lowercase\"]}}}},\"aliases\":{\"haystack-traces\":{}},\"mappings\":{\"spans\":{\"_field_names\":{\"enabled\":false},\"_all\":{\"enabled\":false},\"_source\":{\"includes\":[\"traceid\"]},\"properties\":{\"traceid\":{\"enabled\":false},\"starttime\":{\"type\":\"long\",\"doc_values\": true},\"spans\":{\"type\":\"nested\",\"properties\":{\"servicename\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false},\"operationname\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false},\"starttime\":{\"enabled\":false}}}},\"dynamic_templates\":[{\"strings_as_keywords_1\":{\"match_mapping_type\":\"string\",\"mapping\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false}}},{\"longs_disable_doc_norms\":{\"match_mapping_type\":\"long\",\"mapping\":{\"type\":\"long\",\"doc_values\":false,\"norms\":false}}}]}}}", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092", "vars.span_produce_topic": "" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "2e1f829437687dd2b0d271330c6f08e771df5c05de8fc1582e52d1ce1387b8e5", "attributes": { "id": "2e1f829437687dd2b0d271330c6f08e771df5c05de8fc1582e52d1ce1387b8e5", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: trace-indexer\n name: trace-indexer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: trace-indexer\n template:\n metadata:\n labels:\n k8s-app: trace-indexer\n spec:\n containers:\n - name: storage-backend-cassandra\n image: expediadotcom/haystack-trace-backend-cassandra:316f53fb22b01984099db5c2b99049b703483082\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_PROP_CASSANDRA_ENDPOINTS\"\n value: \"cassandra\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8090\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n - name: trace-indexer\n image: expediadotcom/haystack-trace-indexer:316f53fb22b01984099db5c2b99049b703483082\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/trace-indexer.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n timeoutSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: storage-backend-cassandra\n image: ${storage_backend_image}\n resources:\n limits:\n cpu: ${backend_cpu_limit}\n memory: ${backend_memory_limit}Mi\n requests:\n cpu: ${backend_cpu_request}\n memory: ${backend_memory_request}Mi\n env:\n - name: \"HAYSTACK_PROP_CASSANDRA_ENDPOINTS\"\n value: \"${cassandra_hostname}\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"${graphite_enabled}\"\n - name: \"JAVA_XMS\"\n value: \"${backend_jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${backend_jvm_memory_limit}m\"\n ${backend_env_vars}\n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8090\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n - name: ${app_name}\n image: ${indexer_image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/trace-indexer.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"${graphite_enabled}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n timeoutSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n", "vars.%": "23", "vars.app_name": "trace-indexer", "vars.backend_cpu_limit": "500m", "vars.backend_cpu_request": "100m", "vars.backend_env_vars": "", "vars.backend_jvm_memory_limit": "200", "vars.backend_memory_limit": "250", "vars.backend_memory_request": "250", "vars.cassandra_hostname": "cassandra", "vars.configmap_name": "indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_enabled": "false", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.indexer_image": "expediadotcom/haystack-trace-indexer:316f53fb22b01984099db5c2b99049b703483082", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.storage_backend_image": "expediadotcom/haystack-trace-backend-cassandra:316f53fb22b01984099db5c2b99049b703483082" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "kubernetes_config_map.haystack-config": { "type": "kubernetes_config_map", "depends_on": [ "data.template_file.config_data", "local.configmap_name", "local.count" ], "primary": { "id": "haystack-apps/indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de", "attributes": { "data.%": "1", "data.trace-indexer.conf": "health.status.path = \"/app/isHealthy\"\n\nspan.accumulate {\n store {\n min.traces.per.cache = 1000 # this defines the minimum traces in each cache before eviction check is applied. This is also useful for testing the code\n all.max.entries = 150000 # this is the maximum number of spans that can live across all the stores\n }\n window.ms = 10000\n poll.ms = 2000\n packer = zstd\n}\n\nkafka {\n close.stream.timeout.ms = 15000\n\n topic.consume = \"proto-spans\"\n topic.produce = \"\"\n\n num.stream.threads = 2\n poll.timeout.ms = 100\n\n # if consumer poll hangs, then wakeup it after after a timeout\n # also set the maximum wakeups allowed, if max threshold is reached, then task will raise the shutdown request\n max.wakeups = 10\n wakeup.timeout.ms = 3000\n\n commit.offset {\n retries = 3\n backoff.ms = 200\n }\n\n # consumer specific configurations\n consumer {\n group.id = \"haystack-proto-trace-indexer\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n auto.offset.reset = \"latest\"\n\n # disable auto commit as the app manages offset itself\n enable.auto.commit = \"false\"\n }\n\n # producer specific configurations\n producer {\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n }\n}\n\nbackend {\n\n client {\n host = \"localhost\"\n port = 8090\n }\n # defines the max inflight writes for backend client\n max.inflight.requests = 100\n}\nelasticsearch {\n endpoint = \"http://elasticsearch:9200\"\n\n # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk\n bulk.max {\n docs {\n count = 200\n size.kb = 1000\n }\n inflight = 25\n }\n\n conn.timeout.ms = 10000\n read.timeout.ms = 30000\n consistency.level = \"one\"\n max.connections.per.route = 5\n\n retries {\n max = 10\n backoff {\n initial.ms = 100\n factor = 2\n }\n }\n\n index {\n # apply the template before starting the client, if json is empty, no operation is performed\n template.json = \"\"\"{\"template\":\"haystack-traces*\",\"settings\":{\"number_of_shards\":4,\"index.mapping.ignore_malformed\":true,\"analysis\":{\"normalizer\":{\"lowercase_normalizer\":{\"type\":\"custom\",\"filter\":[\"lowercase\"]}}}},\"aliases\":{\"haystack-traces\":{}},\"mappings\":{\"spans\":{\"_field_names\":{\"enabled\":false},\"_all\":{\"enabled\":false},\"_source\":{\"includes\":[\"traceid\"]},\"properties\":{\"traceid\":{\"enabled\":false},\"starttime\":{\"type\":\"long\",\"doc_values\": true},\"spans\":{\"type\":\"nested\",\"properties\":{\"servicename\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false},\"operationname\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false},\"starttime\":{\"enabled\":false}}}},\"dynamic_templates\":[{\"strings_as_keywords_1\":{\"match_mapping_type\":\"string\",\"mapping\":{\"type\":\"keyword\",\"normalizer\":\"lowercase_normalizer\",\"doc_values\":false,\"norms\":false}}},{\"longs_disable_doc_norms\":{\"match_mapping_type\":\"long\",\"mapping\":{\"type\":\"long\",\"doc_values\":false,\"norms\":false}}}]}}}\"\"\"\n\n name.prefix = \"haystack-traces\"\n type = \"spans\"\n hour.bucket = 6\n }\n}\n\nservice.metadata {\n enabled = true\n flush {\n interval.sec = 60\n operation.count = 10000\n }\n es {\n endpoint = \"http://elasticsearch:9200\"\n conn.timeout.ms = 10000\n read.timeout.ms = 5000\n consistency.level = \"one\"\n index {\n # apply the template before starting the client, if json is empty, no operation is performed\n template.json = \"\"\"{\"template\": \"service-metadata*\", \"aliases\": {\"service-metadata\": {}}, \"settings\": {\"number_of_shards\": 4, \"index.mapping.ignore_malformed\": true, \"analysis\": {\"normalizer\": {\"lowercase_normalizer\": {\"type\": \"custom\", \"filter\": [\"lowercase\"]}}}}, \"mappings\": {\"metadata\": {\"_field_names\": {\"enabled\": false}, \"_all\": {\"enabled\": false}, \"properties\": {\"servicename\": {\"type\": \"keyword\", \"norms\": false}, \"operationname\": {\"type\": \"keyword\", \"doc_values\": false, \"norms\": false}}}}}\"\"\"\n name = \"service-metadata\"\n type = \"metadata\"\n }\n # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk\n bulk.max {\n docs {\n count = 100\n size.kb = 1000\n }\n inflight = 10\n }\n retries {\n max = 10\n backoff {\n initial.ms = 100\n factor = 2\n }\n }\n }\n}\n\nreload {\n tables {\n index.fields.config = \"indexing-fields\"\n }\n config {\n endpoint = \"http://elasticsearch:9200\"\n database.name = \"reload-configs\"\n }\n startup.load = true\n interval.ms = 60000 # -1 will imply 'no reload'\n}\n", "id": "haystack-apps/indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de", "metadata.#": "1", "metadata.0.annotations.%": "0", "metadata.0.generate_name": "", "metadata.0.generation": "0", "metadata.0.labels.%": "0", "metadata.0.name": "indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de", "metadata.0.namespace": "haystack-apps", "metadata.0.resource_version": "7111", "metadata.0.self_link": "/api/v1/namespaces/haystack-apps/configmaps/indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de", "metadata.0.uid": "ebc4bb5d-5aad-11e9-81ac-080027a2c57a" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.kubernetes" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml", "local.count" ], "primary": { "id": "2475808687789377217", "attributes": { "id": "2475808687789377217", "triggers.%": "1", "triggers.template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: trace-indexer\n name: trace-indexer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: trace-indexer\n template:\n metadata:\n labels:\n k8s-app: trace-indexer\n spec:\n containers:\n - name: storage-backend-cassandra\n image: expediadotcom/haystack-trace-backend-cassandra:316f53fb22b01984099db5c2b99049b703483082\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_PROP_CASSANDRA_ENDPOINTS\"\n value: \"cassandra\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8090\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n - name: trace-indexer\n image: expediadotcom/haystack-trace-indexer:316f53fb22b01984099db5c2b99049b703483082\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/trace-indexer.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n timeoutSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: indexer-fd354acb1e5ab3440a27c570d2a2b6561b4c96de\n\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.kubectl_destroy": { "type": "null_resource", "depends_on": [ "local.count" ], "primary": { "id": "6036493350675699407", "attributes": { "id": "6036493350675699407" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "traces", "trace-reader" ], "outputs": { "hostname": { "sensitive": false, "type": "string", "value": "trace-reader" }, "service_port": { "sensitive": false, "type": "string", "value": "8080" } }, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "d366a66e0caf65fe924a594ae3ae601deb6a729faabf04f0945f5009fcddd94b", "attributes": { "id": "d366a66e0caf65fe924a594ae3ae601deb6a729faabf04f0945f5009fcddd94b", "rendered": "service {\n port = 8080\n ssl {\n enabled = false\n cert.path = \"\"\n private.key.path = \"\"\n }\n max.message.size = 52428800 # 50MB in bytes\n}\n\nbackend {\n client {\n host = \"localhost\"\n port = 8090\n }\n}\n\nelasticsearch {\n client {\n endpoint = \"http://elasticsearch:9200\"\n conn.timeout.ms = 10000\n read.timeout.ms = 30000\n }\n index {\n spans {\n name.prefix = \"haystack-traces\"\n type = \"spans\"\n hour.bucket = 6\n hour.ttl = 72 // 3 backend.tf main.tf overrides.json provider.tf variables.tf 24 hours\n use.root.doc.starttime = true\n }\n service.metadata {\n enabled = true\n name = \"service-metadata\"\n type = \"metadata\"\n }\n }\n}\n\ntrace {\n validators {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.validators.TraceIdValidator\"\n ]\n }\n\n transformers {\n pre {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.transformers.DeDuplicateSpanTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ClientServerEventLogTransformer\"\n ]\n }\n post {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.transformers.PartialSpanTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ServerClientSpanMergeTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.InvalidRootTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.InvalidParentTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ClockSkewTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.SortSpanTransformer\"\n ]\n }\n }\n}\n\nreload {\n tables {\n index.fields.config = \"indexing-fields\"\n }\n config {\n endpoint = \"http://elasticsearch:9200\"\n database.name = \"reload-configs\"\n }\n startup.load = true\n interval.ms = 60000 # -1 will imply 'no reload'\n}\n", "template": "service {\n port = 8080\n ssl {\n enabled = false\n cert.path = \"\"\n private.key.path = \"\"\n }\n max.message.size = 52428800 # 50MB in bytes\n}\n\nbackend {\n client {\n host = \"localhost\"\n port = 8090\n }\n}\n\nelasticsearch {\n client {\n endpoint = \"http://${elasticsearch_endpoint}\"\n conn.timeout.ms = 10000\n read.timeout.ms = 30000\n }\n index {\n spans {\n name.prefix = \"haystack-traces\"\n type = \"spans\"\n hour.bucket = 6\n hour.ttl = 72 // 3 backend.tf main.tf overrides.json provider.tf variables.tf 24 hours\n use.root.doc.starttime = true\n }\n service.metadata {\n enabled = true\n name = \"service-metadata\"\n type = \"metadata\"\n }\n }\n}\n\ntrace {\n validators {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.validators.TraceIdValidator\"\n ]\n }\n\n transformers {\n pre {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.transformers.DeDuplicateSpanTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ClientServerEventLogTransformer\"\n ]\n }\n post {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.transformers.PartialSpanTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ServerClientSpanMergeTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.InvalidRootTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.InvalidParentTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ClockSkewTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.SortSpanTransformer\"\n ]\n }\n }\n}\n\nreload {\n tables {\n index.fields.config = \"indexing-fields\"\n }\n config {\n endpoint = \"http://${elasticsearch_endpoint}\"\n database.name = \"reload-configs\"\n }\n startup.load = true\n interval.ms = 60000 # -1 will imply 'no reload'\n}\n", "vars.%": "1", "vars.elasticsearch_endpoint": "elasticsearch:9200" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "36f6f890d01c524b552512feea24f6231b4d6d44b5a5bf4e946fc860b8adaba8", "attributes": { "id": "36f6f890d01c524b552512feea24f6231b4d6d44b5a5bf4e946fc860b8adaba8", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: trace-reader\n name: trace-reader\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: trace-reader\n template:\n metadata:\n labels:\n k8s-app: trace-reader\n spec:\n containers:\n - name: storage-backend-cassandra\n image: expediadotcom/haystack-trace-backend-cassandra:316f53fb22b01984099db5c2b99049b703483082\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_PROP_CASSANDRA_ENDPOINTS\"\n value: \"cassandra\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8090\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n - name: trace-reader\n image: expediadotcom/haystack-trace-reader:316f53fb22b01984099db5c2b99049b703483082\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/trace-reader.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8080\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: trace-reader\n name: trace-reader\n namespace: haystack-apps\nspec:\n ports:\n - port: 8080\n targetPort: 8080\n selector:\n k8s-app: trace-reader\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: storage-backend-cassandra\n image: ${storage_backend_image}\n resources:\n limits:\n cpu: ${backend_cpu_limit}\n memory: ${backend_memory_limit}Mi\n requests:\n cpu: ${backend_cpu_request}\n memory: ${backend_memory_request}Mi\n env:\n - name: \"HAYSTACK_PROP_CASSANDRA_ENDPOINTS\"\n value: \"${cassandra_hostname}\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"${graphite_enabled}\"\n - name: \"JAVA_XMS\"\n value: \"${backend_jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${backend_jvm_memory_limit}m\"\n ${backend_env_vars}\n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8090\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n - name: ${app_name}\n image: ${reader_image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/trace-reader.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"${graphite_enabled}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:${container_port}\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}\n", "vars.%": "25", "vars.app_name": "trace-reader", "vars.backend_cpu_limit": "500m", "vars.backend_cpu_request": "100m", "vars.backend_env_vars": "", "vars.backend_jvm_memory_limit": "200", "vars.backend_memory_limit": "250", "vars.backend_memory_request": "250", "vars.cassandra_hostname": "cassandra", "vars.configmap_name": "reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6", "vars.container_port": "8080", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_enabled": "false", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.reader_image": "expediadotcom/haystack-trace-reader:316f53fb22b01984099db5c2b99049b703483082", "vars.replicas": "1", "vars.service_port": "8080", "vars.storage_backend_image": "expediadotcom/haystack-trace-backend-cassandra:316f53fb22b01984099db5c2b99049b703483082" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "kubernetes_config_map.haystack-config": { "type": "kubernetes_config_map", "depends_on": [ "data.template_file.config_data", "local.configmap_name", "local.count" ], "primary": { "id": "haystack-apps/reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6", "attributes": { "data.%": "1", "data.trace-reader.conf": "service {\n port = 8080\n ssl {\n enabled = false\n cert.path = \"\"\n private.key.path = \"\"\n }\n max.message.size = 52428800 # 50MB in bytes\n}\n\nbackend {\n client {\n host = \"localhost\"\n port = 8090\n }\n}\n\nelasticsearch {\n client {\n endpoint = \"http://elasticsearch:9200\"\n conn.timeout.ms = 10000\n read.timeout.ms = 30000\n }\n index {\n spans {\n name.prefix = \"haystack-traces\"\n type = \"spans\"\n hour.bucket = 6\n hour.ttl = 72 // 3 backend.tf main.tf overrides.json provider.tf variables.tf 24 hours\n use.root.doc.starttime = true\n }\n service.metadata {\n enabled = true\n name = \"service-metadata\"\n type = \"metadata\"\n }\n }\n}\n\ntrace {\n validators {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.validators.TraceIdValidator\"\n ]\n }\n\n transformers {\n pre {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.transformers.DeDuplicateSpanTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ClientServerEventLogTransformer\"\n ]\n }\n post {\n sequence = [\n \"com.expedia.www.haystack.trace.reader.readers.transformers.PartialSpanTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ServerClientSpanMergeTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.InvalidRootTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.InvalidParentTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.ClockSkewTransformer\"\n \"com.expedia.www.haystack.trace.reader.readers.transformers.SortSpanTransformer\"\n ]\n }\n }\n}\n\nreload {\n tables {\n index.fields.config = \"indexing-fields\"\n }\n config {\n endpoint = \"http://elasticsearch:9200\"\n database.name = \"reload-configs\"\n }\n startup.load = true\n interval.ms = 60000 # -1 will imply 'no reload'\n}\n", "id": "haystack-apps/reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6", "metadata.#": "1", "metadata.0.annotations.%": "0", "metadata.0.generate_name": "", "metadata.0.generation": "0", "metadata.0.labels.%": "0", "metadata.0.name": "reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6", "metadata.0.namespace": "haystack-apps", "metadata.0.resource_version": "7110", "metadata.0.self_link": "/api/v1/namespaces/haystack-apps/configmaps/reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6", "metadata.0.uid": "ebc0a7b2-5aad-11e9-81ac-080027a2c57a" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.kubernetes" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml", "local.count" ], "primary": { "id": "7362038791772677591", "attributes": { "id": "7362038791772677591", "triggers.%": "1", "triggers.template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: trace-reader\n name: trace-reader\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: trace-reader\n template:\n metadata:\n labels:\n k8s-app: trace-reader\n spec:\n containers:\n - name: storage-backend-cassandra\n image: expediadotcom/haystack-trace-backend-cassandra:316f53fb22b01984099db5c2b99049b703483082\n resources:\n limits:\n cpu: 500m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_PROP_CASSANDRA_ENDPOINTS\"\n value: \"cassandra\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8090\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n - name: trace-reader\n image: expediadotcom/haystack-trace-reader:316f53fb22b01984099db5c2b99049b703483082\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/trace-reader.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - /bin/grpc_health_probe\n - \"-addr=:8080\"\n initialDelaySeconds: 30\n periodSeconds: 15\n timeoutSeconds: 5\n failureThreshold: 3\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: reader-48f3f74a468b0017ed9cf3ab1fc882c322c2dfd6\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: trace-reader\n name: trace-reader\n namespace: haystack-apps\nspec:\n ports:\n - port: 8080\n targetPort: 8080\n selector:\n k8s-app: trace-reader\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.kubectl_destroy": { "type": "null_resource", "depends_on": [ "local.count" ], "primary": { "id": "2253597351060386697", "attributes": { "id": "2253597351060386697" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "trends", "metrictank" ], "outputs": { "metrictank_hostname": { "sensitive": false, "type": "string", "value": "metrictank" }, "metrictank_port": { "sensitive": false, "type": "string", "value": "6060" } }, "resources": { "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.container_port", "local.deployment_yaml_file_path", "local.image", "local.service_port" ], "primary": { "id": "d03caf311c2050d08a481da2a693805e0c1b40a27f5e36cf57f8b49601b329ac", "attributes": { "id": "d03caf311c2050d08a481da2a693805e0c1b40a27f5e36cf57f8b49601b329ac", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: metrictank\n name: metrictank\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: metrictank\n template:\n metadata:\n labels:\n k8s-app: metrictank\n spec:\n containers:\n - name: metrictank\n image: grafana/metrictank:0.10.1\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"MT_HTTP_MULTI_TENANT\"\n value: \"false\"\n - name: \"MT_CARBON_IN_ENABLED\"\n value: \"false\"\n - name: \"MT_KAFKA_MDM_IN_ENABLED\"\n value: \"true\"\n - name: \"MT_CASSANDRA_ADDRS\"\n value: \"cassandra:9042\"\n - name: \"MT_KAFKA_MDM_IN_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n - name: \"MT_CASSANDRA_IDX_HOSTS\"\n value: \"cassandra:9042\"\n - name: \"MT_STATS_ADDR\"\n value: \"monitoring-influxdb-graphite.kube-system.svc:2003\"\n - name: \"MT_MEMORY_IDX_TAG_SUPPORT\"\n value: \"true\"\n \n nodeSelector:\n kubernetes.io/hostname: minikube\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: metrictank\n name: metrictank\n namespace: haystack-apps\nspec:\n ports:\n - port: 6060\n targetPort: 6060\n selector:\n k8s-app: metrictank\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"MT_HTTP_MULTI_TENANT\"\n value: \"false\"\n - name: \"MT_CARBON_IN_ENABLED\"\n value: \"false\"\n - name: \"MT_KAFKA_MDM_IN_ENABLED\"\n value: \"true\"\n - name: \"MT_CASSANDRA_ADDRS\"\n value: \"${cassandra_address}\"\n - name: \"MT_KAFKA_MDM_IN_BROKERS\"\n value: \"${kafka_address}\"\n - name: \"MT_CASSANDRA_IDX_HOSTS\"\n value: \"${cassandra_address}\"\n - name: \"MT_STATS_ADDR\"\n value: \"${graphite_address}\"\n - name: \"MT_MEMORY_IDX_TAG_SUPPORT\"\n value: \"${tag_support}\"\n ${env_vars}\n nodeSelector:\n ${node_selecter_label}\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n ports:\n - port: ${service_port}\n targetPort: ${container_port}\n selector:\n k8s-app: ${app_name}\n", "vars.%": "17", "vars.app_name": "metrictank", "vars.cassandra_address": "cassandra:9042", "vars.container_port": "6060", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.gra": "monitoring-influxdb-graphite.kube-system.svc:2003", "vars.graphite_address": "monitoring-influxdb-graphite.kube-system.svc:2003", "vars.image": "grafana/metrictank:0.10.1", "vars.kafka_address": "kafka-service.haystack-apps.svc.cluster.local:9092", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1", "vars.service_port": "6060", "vars.tag_support": "true" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml", "local.count" ], "primary": { "id": "4725027806184077583", "attributes": { "id": "4725027806184077583", "triggers.%": "1", "triggers.template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: metrictank\n name: metrictank\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: metrictank\n template:\n metadata:\n labels:\n k8s-app: metrictank\n spec:\n containers:\n - name: metrictank\n image: grafana/metrictank:0.10.1\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"MT_HTTP_MULTI_TENANT\"\n value: \"false\"\n - name: \"MT_CARBON_IN_ENABLED\"\n value: \"false\"\n - name: \"MT_KAFKA_MDM_IN_ENABLED\"\n value: \"true\"\n - name: \"MT_CASSANDRA_ADDRS\"\n value: \"cassandra:9042\"\n - name: \"MT_KAFKA_MDM_IN_BROKERS\"\n value: \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n - name: \"MT_CASSANDRA_IDX_HOSTS\"\n value: \"cassandra:9042\"\n - name: \"MT_STATS_ADDR\"\n value: \"monitoring-influxdb-graphite.kube-system.svc:2003\"\n - name: \"MT_MEMORY_IDX_TAG_SUPPORT\"\n value: \"true\"\n \n nodeSelector:\n kubernetes.io/hostname: minikube\n\n# ------------------- Service ------------------- #\n---\napiVersion: v1\nkind: Service\nmetadata:\n labels:\n k8s-app: metrictank\n name: metrictank\n namespace: haystack-apps\nspec:\n ports:\n - port: 6060\n targetPort: 6060\n selector:\n k8s-app: metrictank\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "trends", "span-timeseries-transformer" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "ef700d8f401039db1e278d05e486abc9bf38dc2dd9cf6c69b1f9de91d058c054", "attributes": { "id": "ef700d8f401039db1e278d05e486abc9bf38dc2dd9cf6c69b1f9de91d058c054", "rendered": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"span-timeseries-transformer-v2\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 3\n commit.interval.ms = 3000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.SpanTimestampExtractor\"\n }\n\n producer {\n topic = \"metric-data-points\"\n }\n\n consumer {\n topic = \"proto-spans\"\n }\n}\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"periodreplacement\"\nenable.metricpoint.service.level.generation = false\n\nblacklist.services = []\n", "template": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"span-timeseries-transformer-v2\"\n bootstrap.servers = \"${kafka_endpoint}\"\n num.stream.threads = 3\n commit.interval.ms = 3000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.SpanTimestampExtractor\"\n }\n\n producer {\n topic = \"metric-data-points\"\n }\n\n consumer {\n topic = \"proto-spans\"\n }\n}\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"${metricpoint_encoder_type}\"\nenable.metricpoint.service.level.generation = false\n\nblacklist.services = []\n", "vars.%": "2", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092", "vars.metricpoint_encoder_type": "periodreplacement" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "53393e3ebab67764a7f3cdc4cb82dcb5874fcdf791cb9e83452ea59e9ab8d80d", "attributes": { "id": "53393e3ebab67764a7f3cdc4cb82dcb5874fcdf791cb9e83452ea59e9ab8d80d", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: span-timeseries-transformer\n name: span-timeseries-transformer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: span-timeseries-transformer\n template:\n metadata:\n labels:\n k8s-app: span-timeseries-transformer\n spec:\n containers:\n - name: span-timeseries-transformer\n image: expediadotcom/haystack-span-timeseries-transformer:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/span-timeseries-transformer.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: transformer-658ea1e33f1104d5b898cc42b21c51debb350a21\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/span-timeseries-transformer.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"${graphite_enabled}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n", "vars.%": "15", "vars.app_name": "span-timeseries-transformer", "vars.configmap_name": "transformer-658ea1e33f1104d5b898cc42b21c51debb350a21", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_enabled": "false", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-span-timeseries-transformer:1.1", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "kubernetes_config_map.haystack-config": { "type": "kubernetes_config_map", "depends_on": [ "data.template_file.config_data", "local.configmap_name", "local.count" ], "primary": { "id": "haystack-apps/transformer-658ea1e33f1104d5b898cc42b21c51debb350a21", "attributes": { "data.%": "1", "data.span-timeseries-transformer.conf": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"span-timeseries-transformer-v2\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 3\n commit.interval.ms = 3000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.SpanTimestampExtractor\"\n }\n\n producer {\n topic = \"metric-data-points\"\n }\n\n consumer {\n topic = \"proto-spans\"\n }\n}\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"periodreplacement\"\nenable.metricpoint.service.level.generation = false\n\nblacklist.services = []\n", "id": "haystack-apps/transformer-658ea1e33f1104d5b898cc42b21c51debb350a21", "metadata.#": "1", "metadata.0.annotations.%": "0", "metadata.0.generate_name": "", "metadata.0.generation": "0", "metadata.0.labels.%": "0", "metadata.0.name": "transformer-658ea1e33f1104d5b898cc42b21c51debb350a21", "metadata.0.namespace": "haystack-apps", "metadata.0.resource_version": "515", "metadata.0.self_link": "/api/v1/namespaces/haystack-apps/configmaps/transformer-658ea1e33f1104d5b898cc42b21c51debb350a21", "metadata.0.uid": "dadbad6c-5a8e-11e9-82ec-080027a2c57a" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.kubernetes" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml", "local.count" ], "primary": { "id": "1053676939533131096", "attributes": { "id": "1053676939533131096", "triggers.%": "1", "triggers.template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: span-timeseries-transformer\n name: span-timeseries-transformer\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: span-timeseries-transformer\n template:\n metadata:\n labels:\n k8s-app: span-timeseries-transformer\n spec:\n containers:\n - name: span-timeseries-transformer\n image: expediadotcom/haystack-span-timeseries-transformer:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/span-timeseries-transformer.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: transformer-658ea1e33f1104d5b898cc42b21c51debb350a21\n\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.kubectl_destroy": { "type": "null_resource", "depends_on": [ "local.count" ], "primary": { "id": "4491905015242679027", "attributes": { "id": "4491905015242679027" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "trends", "timeseries-aggregator" ], "outputs": {}, "resources": { "data.template_file.config_data": { "type": "template_file", "depends_on": [ "local.config_file_path" ], "primary": { "id": "20797058d7274d5af393bcd783f0e9dbe69155367bf65fbce7f3e372ca7c31df", "attributes": { "id": "20797058d7274d5af393bcd783f0e9dbe69155367bf65fbce7f3e372ca7c31df", "rendered": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"timeseries-aggregator-v2\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 2\n commit.interval.ms = 5000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.MetricDataTimestampExtractor\"\n consumer.heartbeat.interval.ms = 30000\n consumer.session.timeout.ms = 100000\n consumer.max.partition.fetch.bytes = 262144\n }\n\n // For producing data to external kafka: set enable.external.kafka.produce to true and uncomment the props.\n // For producing to same kafka: set enable.external.kafka.produce to false and comment the props.\n producer {\n topics : [\n {\n topic: \"metrics\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricDataSerde\"\n enabled: true\n },\n {\n topic: \"mdm\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricTankSerde\"\n enabled: true\n }\n ]\n enable.external.kafka.produce = false\n external.kafka.topic = \"mdm\"\n props {\n bootstrap.servers = \":9092\"\n retries = 50\n batch.size = 65536\n linger.ms = 250\n }\n }\n\n consumer {\n topic = \"metric-data-points\"\n }\n}\n\nstate.store {\n enable.logging = true\n logging.delay.seconds = 60\n\n // It is capacity for the trends to be kept in memory before flushing it to state store\n cache.size = 3000\n changelog.topic {\n cleanup.policy = \"compact,delete\"\n retention.ms = 14400000 // 4Hrs\n }\n}\n\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"periodreplacement\"\n\nhistogram {\n max.value = \"1800000\"\n precision = \"2\"\n value.unit = \"millis\" // can be micros / millis / seconds\n}\n", "template": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"timeseries-aggregator-v2\"\n bootstrap.servers = \"${kafka_endpoint}\"\n num.stream.threads = 2\n commit.interval.ms = 5000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.MetricDataTimestampExtractor\"\n consumer.heartbeat.interval.ms = 30000\n consumer.session.timeout.ms = 100000\n consumer.max.partition.fetch.bytes = 262144\n }\n\n // For producing data to external kafka: set enable.external.kafka.produce to true and uncomment the props.\n // For producing to same kafka: set enable.external.kafka.produce to false and comment the props.\n producer {\n topics : [\n {\n topic: \"metrics\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricDataSerde\"\n enabled: ${enable_metrics_sink}\n },\n {\n topic: \"mdm\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricTankSerde\"\n enabled: true\n }\n ]\n enable.external.kafka.produce = ${enable_external_kafka_producer}\n external.kafka.topic = \"mdm\"\n props {\n bootstrap.servers = \"${external_kafka_producer_endpoint}\"\n retries = 50\n batch.size = 65536\n linger.ms = 250\n }\n }\n\n consumer {\n topic = \"metric-data-points\"\n }\n}\n\nstate.store {\n enable.logging = true\n logging.delay.seconds = 60\n\n // It is capacity for the trends to be kept in memory before flushing it to state store\n cache.size = 3000\n changelog.topic {\n cleanup.policy = \"compact,delete\"\n retention.ms = 14400000 // 4Hrs\n }\n}\n\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"${metricpoint_encoder_type}\"\n\nhistogram {\n max.value = \"${histogram_max_value}\"\n precision = \"${histogram_precision}\"\n value.unit = \"${histogram_value_unit}\" // can be micros / millis / seconds\n}\n", "vars.%": "8", "vars.enable_external_kafka_producer": "false", "vars.enable_metrics_sink": "true", "vars.external_kafka_producer_endpoint": ":9092", "vars.histogram_max_value": "1800000", "vars.histogram_precision": "2", "vars.histogram_value_unit": "millis", "vars.kafka_endpoint": "kafka-service.haystack-apps.svc.cluster.local:9092", "vars.metricpoint_encoder_type": "periodreplacement" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "data.template_file.deployment_yaml": { "type": "template_file", "depends_on": [ "data.template_file.config_data", "local.app_name", "local.configmap_name", "local.deployment_yaml_file_path" ], "primary": { "id": "850b3e97210d77bc00563cdb56b19df1584349a1f8467179b868934c876c4ed7", "attributes": { "id": "850b3e97210d77bc00563cdb56b19df1584349a1f8467179b868934c876c4ed7", "rendered": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: timeseries-aggregator\n name: timeseries-aggregator\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: timeseries-aggregator\n template:\n metadata:\n labels:\n k8s-app: timeseries-aggregator\n spec:\n containers:\n - name: timeseries-aggregator\n image: expediadotcom/haystack-timeseries-aggregator:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/timeseries-aggregator.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: aggregator-4b739edf87c39524a8724d5d8578d93be63240c7\n\n", "template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: ${app_name}\n name: ${app_name}\n namespace: ${namespace}\nspec:\n replicas: ${replicas}\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: ${app_name}\n template:\n metadata:\n labels:\n k8s-app: ${app_name}\n spec:\n containers:\n - name: ${app_name}\n image: ${image}\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: ${cpu_limit}\n memory: ${memory_limit}Mi\n requests:\n cpu: ${cpu_request}\n memory: ${memory_request}Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/timeseries-aggregator.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"${graphite_host}\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"${graphite_port}\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"${graphite_enabled}\"\n - name: \"JAVA_XMS\"\n value: \"${jvm_memory_limit}m\"\n - name: \"JAVA_XMX\"\n value: \"${jvm_memory_limit}m\"\n ${env_vars}\n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n ${node_selecter_label}\n volumes:\n - name: config-volume\n configMap:\n name: ${configmap_name}\n\n", "vars.%": "16", "vars.app_name": "timeseries-aggregator", "vars.config": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"timeseries-aggregator-v2\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 2\n commit.interval.ms = 5000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.MetricDataTimestampExtractor\"\n consumer.heartbeat.interval.ms = 30000\n consumer.session.timeout.ms = 100000\n consumer.max.partition.fetch.bytes = 262144\n }\n\n // For producing data to external kafka: set enable.external.kafka.produce to true and uncomment the props.\n // For producing to same kafka: set enable.external.kafka.produce to false and comment the props.\n producer {\n topics : [\n {\n topic: \"metrics\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricDataSerde\"\n enabled: true\n },\n {\n topic: \"mdm\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricTankSerde\"\n enabled: true\n }\n ]\n enable.external.kafka.produce = false\n external.kafka.topic = \"mdm\"\n props {\n bootstrap.servers = \":9092\"\n retries = 50\n batch.size = 65536\n linger.ms = 250\n }\n }\n\n consumer {\n topic = \"metric-data-points\"\n }\n}\n\nstate.store {\n enable.logging = true\n logging.delay.seconds = 60\n\n // It is capacity for the trends to be kept in memory before flushing it to state store\n cache.size = 3000\n changelog.topic {\n cleanup.policy = \"compact,delete\"\n retention.ms = 14400000 // 4Hrs\n }\n}\n\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"periodreplacement\"\n\nhistogram {\n max.value = \"1800000\"\n precision = \"2\"\n value.unit = \"millis\" // can be micros / millis / seconds\n}\n", "vars.configmap_name": "aggregator-4b739edf87c39524a8724d5d8578d93be63240c7", "vars.cpu_limit": "1000m", "vars.cpu_request": "100m", "vars.env_vars": "", "vars.graphite_enabled": "false", "vars.graphite_host": "monitoring-influxdb-graphite.kube-system.svc", "vars.graphite_port": "2003", "vars.image": "expediadotcom/haystack-timeseries-aggregator:1.1", "vars.jvm_memory_limit": "200", "vars.memory_limit": "250", "vars.memory_request": "250", "vars.namespace": "haystack-apps", "vars.node_selecter_label": "kubernetes.io/hostname: minikube", "vars.replicas": "1" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "kubernetes_config_map.haystack-config": { "type": "kubernetes_config_map", "depends_on": [ "data.template_file.config_data", "local.configmap_name", "local.count" ], "primary": { "id": "haystack-apps/aggregator-4b739edf87c39524a8724d5d8578d93be63240c7", "attributes": { "data.%": "1", "data.timeseries-aggregator.conf": "health.status.path = \"/app/isHealthy\"\n\nkafka {\n close.timeout.ms = 30000\n\n streams {\n application.id = \"timeseries-aggregator-v2\"\n bootstrap.servers = \"kafka-service.haystack-apps.svc.cluster.local:9092\"\n num.stream.threads = 2\n commit.interval.ms = 5000\n auto.offset.reset = latest\n timestamp.extractor = \"com.expedia.www.haystack.commons.kstreams.MetricDataTimestampExtractor\"\n consumer.heartbeat.interval.ms = 30000\n consumer.session.timeout.ms = 100000\n consumer.max.partition.fetch.bytes = 262144\n }\n\n // For producing data to external kafka: set enable.external.kafka.produce to true and uncomment the props.\n // For producing to same kafka: set enable.external.kafka.produce to false and comment the props.\n producer {\n topics : [\n {\n topic: \"metrics\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricDataSerde\"\n enabled: true\n },\n {\n topic: \"mdm\"\n serdeClassName : \"com.expedia.www.haystack.commons.kstreams.serde.metricdata.MetricTankSerde\"\n enabled: true\n }\n ]\n enable.external.kafka.produce = false\n external.kafka.topic = \"mdm\"\n props {\n bootstrap.servers = \":9092\"\n retries = 50\n batch.size = 65536\n linger.ms = 250\n }\n }\n\n consumer {\n topic = \"metric-data-points\"\n }\n}\n\nstate.store {\n enable.logging = true\n logging.delay.seconds = 60\n\n // It is capacity for the trends to be kept in memory before flushing it to state store\n cache.size = 3000\n changelog.topic {\n cleanup.policy = \"compact,delete\"\n retention.ms = 14400000 // 4Hrs\n }\n}\n\n\n// there are three types of encoders that are used on service and operation names:\n// 1) periodreplacement: replaces all periods with 3 underscores\n// 2) base64: base64 encodes the full name with a padding of _\n// 3) noop: does not perform any encoding\nmetricpoint.encoder.type = \"periodreplacement\"\n\nhistogram {\n max.value = \"1800000\"\n precision = \"2\"\n value.unit = \"millis\" // can be micros / millis / seconds\n}\n", "id": "haystack-apps/aggregator-4b739edf87c39524a8724d5d8578d93be63240c7", "metadata.#": "1", "metadata.0.annotations.%": "0", "metadata.0.generate_name": "", "metadata.0.generation": "0", "metadata.0.labels.%": "0", "metadata.0.name": "aggregator-4b739edf87c39524a8724d5d8578d93be63240c7", "metadata.0.namespace": "haystack-apps", "metadata.0.resource_version": "514", "metadata.0.self_link": "/api/v1/namespaces/haystack-apps/configmaps/aggregator-4b739edf87c39524a8724d5d8578d93be63240c7", "metadata.0.uid": "dabc9241-5a8e-11e9-82ec-080027a2c57a" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.kubernetes" }, "null_resource.kubectl_apply": { "type": "null_resource", "depends_on": [ "data.template_file.deployment_yaml", "local.count" ], "primary": { "id": "4430993579978687372", "attributes": { "id": "4430993579978687372", "triggers.%": "1", "triggers.template": "# ------------------- Deployment ------------------- #\n\nkind: Deployment\napiVersion: apps/v1beta2\nmetadata:\n labels:\n k8s-app: timeseries-aggregator\n name: timeseries-aggregator\n namespace: haystack-apps\nspec:\n replicas: 1\n revisionHistoryLimit: 10\n selector:\n matchLabels:\n k8s-app: timeseries-aggregator\n template:\n metadata:\n labels:\n k8s-app: timeseries-aggregator\n spec:\n containers:\n - name: timeseries-aggregator\n image: expediadotcom/haystack-timeseries-aggregator:1.1\n volumeMounts:\n # Create on-disk volume to store exec logs\n - mountPath: /config\n name: config-volume\n resources:\n limits:\n cpu: 1000m\n memory: 250Mi\n requests:\n cpu: 100m\n memory: 250Mi\n env:\n - name: \"HAYSTACK_OVERRIDES_CONFIG_PATH\"\n value: \"/config/timeseries-aggregator.conf\"\n - name: \"HAYSTACK_GRAPHITE_HOST\"\n value: \"monitoring-influxdb-graphite.kube-system.svc\"\n - name: \"HAYSTACK_GRAPHITE_PORT\"\n value: \"2003\"\n - name: \"HAYSTACK_GRAPHITE_ENABLED\"\n value: \"false\"\n - name: \"JAVA_XMS\"\n value: \"200m\"\n - name: \"JAVA_XMX\"\n value: \"200m\"\n \n livenessProbe:\n exec:\n command:\n - grep\n - \"true\"\n - /app/isHealthy\n initialDelaySeconds: 30\n periodSeconds: 5\n failureThreshold: 6\n nodeSelector:\n kubernetes.io/hostname: minikube\n volumes:\n - name: config-volume\n configMap:\n name: aggregator-4b739edf87c39524a8724d5d8578d93be63240c7\n\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" }, "null_resource.kubectl_destroy": { "type": "null_resource", "depends_on": [ "local.count" ], "primary": { "id": "194324143050222949", "attributes": { "id": "194324143050222949" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "traces", "es-indices", "curator_service_metadata" ], "outputs": {}, "resources": { "data.template_file.curator_cron_job": { "type": "template_file", "depends_on": [], "primary": { "id": "660231126a41242563c3c59db32f2a3c93d4eb362eafa5f9082417346440352e", "attributes": { "id": "660231126a41242563c3c59db32f2a3c93d4eb362eafa5f9082417346440352e", "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-service-metadata-index-store\n namespace: haystack-apps\n labels:\n app: curator-es-service-metadata-index-store\ndata:\n curator.yml: |-\n client:\n hosts:\n - elasticsearch\n port: 9200\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: DEBUG\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: service-metadata-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y-%m-%d\"\n unit: days\n unit_count: 4\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-service-metadata-index-store\n namespace: haystack-apps\n\nspec:\n schedule: \"0 */4 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-service-metadata-index-store\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n volumes:\n - name: config\n configMap:\n name: curator-es-service-metadata-index-store\n", "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-service-metadata-index-store\n namespace: ${app_namespace}\n labels:\n app: curator-es-service-metadata-index-store\ndata:\n curator.yml: |-\n client:\n hosts:\n - ${elasticsearch_host}\n port: ${elasticsearch_port}\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: DEBUG\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: service-metadata-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y-%m-%d\"\n unit: days\n unit_count: 4\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-service-metadata-index-store\n namespace: ${app_namespace}\n\nspec:\n schedule: \"0 */4 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-service-metadata-index-store\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n volumes:\n - name: config\n configMap:\n name: curator-es-service-metadata-index-store\n", "vars.%": "3", "vars.app_namespace": "haystack-apps", "vars.elasticsearch_host": "elasticsearch", "vars.elasticsearch_port": "9200" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.curator_addons": { "type": "null_resource", "depends_on": [ "data.template_file.curator_cron_job", "local.count" ], "primary": { "id": "7365091318012467073", "attributes": { "id": "7365091318012467073", "triggers.%": "1", "triggers.template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-service-metadata-index-store\n namespace: haystack-apps\n labels:\n app: curator-es-service-metadata-index-store\ndata:\n curator.yml: |-\n client:\n hosts:\n - elasticsearch\n port: 9200\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: DEBUG\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: service-metadata-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y-%m-%d\"\n unit: days\n unit_count: 4\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-service-metadata-index-store\n namespace: haystack-apps\n\nspec:\n schedule: \"0 */4 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-service-metadata-index-store\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n volumes:\n - name: config\n configMap:\n name: curator-es-service-metadata-index-store\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "traces", "es-indices", "curator_trace_index" ], "outputs": {}, "resources": { "data.template_file.curator_cron_job": { "type": "template_file", "depends_on": [], "primary": { "id": "3ff26510e7b2a04ba06a405fcae7c1d5dcf9d6c88110170ade760e73a0e29227", "attributes": { "id": "3ff26510e7b2a04ba06a405fcae7c1d5dcf9d6c88110170ade760e73a0e29227", "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-haystack-traces-index-store\n namespace: haystack-apps\n labels:\n app: curator-es-haystack-traces-index-store\ndata:\n curator.yml: |-\n client:\n hosts:\n - elasticsearch\n port: 9200\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: DEBUG\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: haystack-traces-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y-%m-%d\"\n unit: days\n unit_count: 4\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-haystack-traces-index-store\n namespace: haystack-apps\n\nspec:\n schedule: \"0 */4 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-haystack-traces-index-store\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n volumes:\n - name: config\n configMap:\n name: curator-es-haystack-traces-index-store\n", "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-haystack-traces-index-store\n namespace: ${app_namespace}\n labels:\n app: curator-es-haystack-traces-index-store\ndata:\n curator.yml: |-\n client:\n hosts:\n - ${elasticsearch_host}\n port: ${elasticsearch_port}\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: DEBUG\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: haystack-traces-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y-%m-%d\"\n unit: days\n unit_count: 4\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-haystack-traces-index-store\n namespace: ${app_namespace}\n\nspec:\n schedule: \"0 */4 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-haystack-traces-index-store\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n volumes:\n - name: config\n configMap:\n name: curator-es-haystack-traces-index-store\n", "vars.%": "3", "vars.app_namespace": "haystack-apps", "vars.elasticsearch_host": "elasticsearch", "vars.elasticsearch_port": "9200" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.curator_addons": { "type": "null_resource", "depends_on": [ "data.template_file.curator_cron_job", "local.count" ], "primary": { "id": "1883447284989104984", "attributes": { "id": "1883447284989104984", "triggers.%": "1", "triggers.template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: curator-es-haystack-traces-index-store\n namespace: haystack-apps\n labels:\n app: curator-es-haystack-traces-index-store\ndata:\n curator.yml: |-\n client:\n hosts:\n - elasticsearch\n port: 9200\n url_prefix:\n use_ssl: False\n certificate:\n client_cert:\n client_key:\n aws_key:\n aws_secret_key:\n aws_region:\n ssl_no_validate: False\n http_auth:\n timeout: 30\n master_only: False\n logging:\n loglevel: DEBUG\n logfile:\n logformat: default\n blacklist: ['elasticsearch', 'urllib3']\n actions.yml: |-\n actions:\n 1:\n action: delete_indices\n options:\n ignore_empty_list: True\n timeout_override:\n continue_if_exception: False\n disable_action: False\n filters:\n - filtertype: pattern\n kind: prefix\n value: haystack-traces-\n exclude:\n - filtertype: age\n source: name\n direction: older\n timestring: \"%Y-%m-%d\"\n unit: days\n unit_count: 4\n exclude:\n---\napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n name: curator-es-haystack-traces-index-store\n namespace: haystack-apps\n\nspec:\n schedule: \"0 */4 backend.tf main.tf overrides.json provider.tf variables.tf backend.tf main.tf overrides.json provider.tf variables.tf *\"\n jobTemplate:\n spec:\n template:\n spec:\n containers:\n - name: curator-es-haystack-traces-index-store\n image: bobrik/curator:5.4.0\n args:\n - --config\n - /config/curator.yml\n - /config/actions.yml\n volumeMounts:\n - mountPath: /config\n name: config\n restartPolicy: OnFailure\n volumes:\n - name: config\n configMap:\n name: curator-es-haystack-traces-index-store\n" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] }, { "path": [ "root", "haystack-apps", "traces", "es-indices", "whitelisted_fields" ], "outputs": {}, "resources": { "data.template_file.whitelisted-fields-pod-yaml": { "type": "template_file", "depends_on": [], "primary": { "id": "953126b2a4ddbbcfde16c45290bbf7b907329aa8904604c4c44c07e0af5dd2eb", "attributes": { "id": "953126b2a4ddbbcfde16c45290bbf7b907329aa8904604c4c44c07e0af5dd2eb", "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: whitelist-json\n namespace: haystack-apps\ndata:\n whitelist.json: |-\n {\n \"fields\": [{\n \"name\": \"error\",\n \"type\": \"string\",\n \"enabled\": true,\n \"searchContext\": \"trace\"\n }]\n }\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n name: es-whitelist\n namespace: haystack-apps\nspec:\n template:\n spec:\n containers:\n - name: es-whitelist\n image: yauritux/busybox-curl\n command:\n - curl\n args:\n - -XPUT\n - -H\n - \"Content-Type: application/json\"\n - -d\n - \"@/data/whitelist.json\"\n - \"http://elasticsearch:9200/reload-configs/indexing-fields/1\"\n volumeMounts:\n - mountPath: /data\n name: data\n restartPolicy: OnFailure\n volumes:\n - name: data\n configMap:\n name: whitelist-json", "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: whitelist-json\n namespace: ${app_namespace}\ndata:\n whitelist.json: |-\n {\n \"fields\": [{\n \"name\": \"error\",\n \"type\": \"string\",\n \"enabled\": true,\n \"searchContext\": \"trace\"\n }]\n }\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n name: es-whitelist\n namespace: ${app_namespace}\nspec:\n template:\n spec:\n containers:\n - name: es-whitelist\n image: yauritux/busybox-curl\n command:\n - curl\n args:\n - -XPUT\n - -H\n - \"Content-Type: application/json\"\n - -d\n - \"@/data/whitelist.json\"\n - \"http://${elasticsearch_host}:${elasticsearch_port}/reload-configs/indexing-fields/1\"\n volumeMounts:\n - mountPath: /data\n name: data\n restartPolicy: OnFailure\n volumes:\n - name: data\n configMap:\n name: whitelist-json", "vars.%": "3", "vars.app_namespace": "haystack-apps", "vars.elasticsearch_host": "elasticsearch", "vars.elasticsearch_port": "9200" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.template" }, "null_resource.whitelisted-fields-pod": { "type": "null_resource", "depends_on": [ "data.template_file.whitelisted-fields-pod-yaml", "local.count" ], "primary": { "id": "3020788302250321366", "attributes": { "id": "3020788302250321366", "triggers.%": "1", "triggers.template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n name: whitelist-json\n namespace: haystack-apps\ndata:\n whitelist.json: |-\n {\n \"fields\": [{\n \"name\": \"error\",\n \"type\": \"string\",\n \"enabled\": true,\n \"searchContext\": \"trace\"\n }]\n }\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n name: es-whitelist\n namespace: haystack-apps\nspec:\n template:\n spec:\n containers:\n - name: es-whitelist\n image: yauritux/busybox-curl\n command:\n - curl\n args:\n - -XPUT\n - -H\n - \"Content-Type: application/json\"\n - -d\n - \"@/data/whitelist.json\"\n - \"http://elasticsearch:9200/reload-configs/indexing-fields/1\"\n volumeMounts:\n - mountPath: /data\n name: data\n restartPolicy: OnFailure\n volumes:\n - name: data\n configMap:\n name: whitelist-json" }, "meta": {}, "tainted": false }, "deposed": [], "provider": "provider.null" } }, "depends_on": [] } ] }}
